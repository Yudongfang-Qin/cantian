

SQL> DROP USER IF EXISTS MOPRODUCTDB CASCADE;

Succeed.

SQL> 
SQL> CREATE USER MOPRODUCTDB IDENTIFIED BY Cantian_234;

Succeed.

SQL> GRANT DBA TO MOPRODUCTDB;

Succeed.

SQL> CONN MOPRODUCTDB/Cantian_234@127.0.0.1:1611

connected.

SQL> 
SQL> CREATE TABLE "MOPRODUCTDB_T_PRODUCT"
  2 (
  3   "ID" VARCHAR(36 BYTE) NOT NULL,
  4   "SERVICE_TYPE" VARCHAR(32 BYTE) NOT NULL,
  5   "CREATE_VDC_ID" VARCHAR(64 BYTE),
  6   "CREATE_USER_ID" VARCHAR(64 BYTE),
  7   "ICON_ID" VARCHAR(36 BYTE),
  8   "CATALOG_ID" VARCHAR(36 BYTE),
  9   "REGION_ID" VARCHAR(128 BYTE) DEFAULT '',
 10   "PARAMS" CLOB,
 11   "SECRET_PARAMS" CLOB,
 12   "NAME" VARCHAR(8000 BYTE) NOT NULL,
 13   "DESCRIPTION" VARCHAR(8000 BYTE),
 14   "CREATE_TIME" DATE DEFAULT CURRENT_TIMESTAMP,
 15   "PUBLISH_STATUS" VARCHAR(32 BYTE) DEFAULT 'draft',
 16   "DELETABLE_STATUS" VARCHAR(32 BYTE) DEFAULT 'normal',
 17   "IS_DEFAULT" BINARY_INTEGER DEFAULT 0,
 18   "RESOURCE_POOL_ID" VARCHAR(128 BYTE) DEFAULT '',
 19   "PROJECT_ID" VARCHAR(128 BYTE) DEFAULT '',
 20   "AZ_ID" VARCHAR(128 BYTE) DEFAULT '',
 21   "EXTEND1" VARCHAR(128 BYTE),
 22   "EXTEND2" VARCHAR(128 BYTE),
 23   "EXTEND3" BINARY_INTEGER,
 24   "EXTEND4" BINARY_BIGINT,
 25   "PRODUCT_TYPE" VARCHAR(32 BYTE),
 26   PRIMARY KEY("ID")
 27 );

Succeed.

SQL> 
SQL> load data infile "./sql/gs_exp_imp_T_PRODUCT.dat" 
  2 into table MOPRODUCTDB_T_PRODUCT 
  3 FIELDS ENCLOSED by '\v' 
  4 FIELDS TERMINATED BY '\f' 
  5 ROWS TERMINATED BY '\a';
39 rows have been committed.
194 rows have been committed.
199 rows have been committed.

Complete the data load.
totally read rows: 199
     ignored rows: 0
      loaded rows: 199
   committed rows: 199
       error rows: 0
        skip rows: 0
SQL> 
SQL> -- copy MOPRODUCTDB_T_PRODUCT for check results
SQL> CREATE TABLE COPY_T_PRODUCT AS SELECT * FROM MOPRODUCTDB_T_PRODUCT;

Succeed.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from COPY_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)) from COPY_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))           
---------------------- ---------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                    

1 rows fetched.

SQL> 
SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL1 INT);

Succeed.

SQL> 
SQL> \! rm -rf moproductdb_dir/


SQL> \! mkdir  moproductdb_dir


SQL> 
SQL> EXP TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_col1.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/add_col1.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

Logical export succeeded.

SQL> 
SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> 
SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_col1.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/add_col1.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)), sum(ADD_COL1) from MOPRODUCTDB_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))            SUM(ADD_COL1)       
---------------------- ---------------------- ---------------------------------------- --------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                                         

1 rows fetched.

SQL> 
SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL2 NUMBER default sin(0.3));

Succeed.

SQL> 
SQL> EXP TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_col2.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/add_col2.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> 
SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_col2.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/add_col2.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)), sum(ADD_COL1), sum(ADD_COL2) from MOPRODUCTDB_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))            SUM(ADD_COL1)        SUM(ADD_COL2)                           
---------------------- ---------------------- ---------------------------------------- -------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                                          58.8085211256065754459588283913204473619

1 rows fetched.

SQL> select ADD_COL1, ADD_COL2 from MOPRODUCTDB_T_PRODUCT limit 1;

ADD_COL1     ADD_COL2                                
------------ ----------------------------------------
             .295520206661339575105320745685027373678

1 rows fetched.

SQL> 
SQL> alter table MOPRODUCTDB_T_PRODUCT drop DESCRIPTION;

Succeed.

SQL> 
SQL> desc MOPRODUCTDB_T_PRODUCT

Name                                Null?    Type                                
----------------------------------- -------- ------------------------------------
ID                                  NOT NULL VARCHAR(36 BYTE)                    
SERVICE_TYPE                        NOT NULL VARCHAR(32 BYTE)                    
CREATE_VDC_ID                                VARCHAR(64 BYTE)                    
CREATE_USER_ID                               VARCHAR(64 BYTE)                    
ICON_ID                                      VARCHAR(36 BYTE)                    
CATALOG_ID                                   VARCHAR(36 BYTE)                    
REGION_ID                                    VARCHAR(128 BYTE)                   
PARAMS                                       CLOB                                
SECRET_PARAMS                                CLOB                                
NAME                                NOT NULL VARCHAR(8000 BYTE)                  
CREATE_TIME                                  DATE                                
PUBLISH_STATUS                               VARCHAR(32 BYTE)                    
DELETABLE_STATUS                             VARCHAR(32 BYTE)                    
IS_DEFAULT                                   BINARY_INTEGER                      
RESOURCE_POOL_ID                             VARCHAR(128 BYTE)                   
PROJECT_ID                                   VARCHAR(128 BYTE)                   
AZ_ID                                        VARCHAR(128 BYTE)                   
EXTEND1                                      VARCHAR(128 BYTE)                   
EXTEND2                                      VARCHAR(128 BYTE)                   
EXTEND3                                      BINARY_INTEGER                      
EXTEND4                                      BINARY_BIGINT                       
PRODUCT_TYPE                                 VARCHAR(32 BYTE)                    
ADD_COL1                                     BINARY_INTEGER                      
ADD_COL2                                     NUMBER                              

SQL> EXP TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/drop_desc.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/drop_desc.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/drop_desc.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/drop_desc.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)), sum(ADD_COL1), sum(ADD_COL2) from MOPRODUCTDB_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))            SUM(ADD_COL1)        SUM(ADD_COL2)                           
---------------------- ---------------------- ---------------------------------------- -------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                                          58.8085211256065754459588283913204473619

1 rows fetched.

SQL> select ADD_COL1, ADD_COL2 from MOPRODUCTDB_T_PRODUCT limit 1;

ADD_COL1     ADD_COL2                                
------------ ----------------------------------------
             .295520206661339575105320745685027373678

1 rows fetched.

SQL> 
SQL> select sum(length(DESCRIPTION)) from MOPRODUCTDB_T_PRODUCT;

CT-00601, [1:19]Sql syntax error: invalid column name 'DESCRIPTION'
SQL> 
SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> CREATE TABLE MOPRODUCTDB_T_PRODUCT AS SELECT * FROM COPY_T_PRODUCT;

Succeed.

SQL> 
SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL1 INT);

Succeed.

SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL2 NUMBER default sin(0.3));

Succeed.

SQL> 
SQL> desc MOPRODUCTDB_T_PRODUCT

Name                                Null?    Type                                
----------------------------------- -------- ------------------------------------
ID                                  NOT NULL VARCHAR(36 BYTE)                    
SERVICE_TYPE                        NOT NULL VARCHAR(32 BYTE)                    
CREATE_VDC_ID                                VARCHAR(64 BYTE)                    
CREATE_USER_ID                               VARCHAR(64 BYTE)                    
ICON_ID                                      VARCHAR(36 BYTE)                    
CATALOG_ID                                   VARCHAR(36 BYTE)                    
REGION_ID                                    VARCHAR(128 BYTE)                   
PARAMS                                       CLOB                                
SECRET_PARAMS                                CLOB                                
NAME                                NOT NULL VARCHAR(8000 BYTE)                  
DESCRIPTION                                  VARCHAR(8000 BYTE)                  
CREATE_TIME                                  DATE                                
PUBLISH_STATUS                               VARCHAR(32 BYTE)                    
DELETABLE_STATUS                             VARCHAR(32 BYTE)                    
IS_DEFAULT                                   BINARY_INTEGER                      
RESOURCE_POOL_ID                             VARCHAR(128 BYTE)                   
PROJECT_ID                                   VARCHAR(128 BYTE)                   
AZ_ID                                        VARCHAR(128 BYTE)                   
EXTEND1                                      VARCHAR(128 BYTE)                   
EXTEND2                                      VARCHAR(128 BYTE)                   
EXTEND3                                      BINARY_INTEGER                      
EXTEND4                                      BINARY_BIGINT                       
PRODUCT_TYPE                                 VARCHAR(32 BYTE)                    
ADD_COL1                                     BINARY_INTEGER                      
ADD_COL2                                     NUMBER                              

SQL> EXP TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_two.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/add_two.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_two.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/add_two.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)), sum(ADD_COL1), sum(ADD_COL2) from MOPRODUCTDB_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))            SUM(ADD_COL1)        SUM(ADD_COL2)                           
---------------------- ---------------------- ---------------------------------------- -------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                                          58.8085211256065754459588283913204473619

1 rows fetched.

SQL> select ADD_COL1, ADD_COL2 from MOPRODUCTDB_T_PRODUCT limit 1;

ADD_COL1     ADD_COL2                                
------------ ----------------------------------------
             .295520206661339575105320745685027373678

1 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> CREATE TABLE MOPRODUCTDB_T_PRODUCT AS SELECT * FROM COPY_T_PRODUCT;

Succeed.

SQL> 
SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL1 INT);

Succeed.

SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT ADD (ADD_COL2 NUMBER default sin(0.3));

Succeed.

SQL> alter table MOPRODUCTDB_T_PRODUCT drop DESCRIPTION;

Succeed.

SQL> 
SQL> desc MOPRODUCTDB_T_PRODUCT

Name                                Null?    Type                                
----------------------------------- -------- ------------------------------------
ID                                  NOT NULL VARCHAR(36 BYTE)                    
SERVICE_TYPE                        NOT NULL VARCHAR(32 BYTE)                    
CREATE_VDC_ID                                VARCHAR(64 BYTE)                    
CREATE_USER_ID                               VARCHAR(64 BYTE)                    
ICON_ID                                      VARCHAR(36 BYTE)                    
CATALOG_ID                                   VARCHAR(36 BYTE)                    
REGION_ID                                    VARCHAR(128 BYTE)                   
PARAMS                                       CLOB                                
SECRET_PARAMS                                CLOB                                
NAME                                NOT NULL VARCHAR(8000 BYTE)                  
CREATE_TIME                                  DATE                                
PUBLISH_STATUS                               VARCHAR(32 BYTE)                    
DELETABLE_STATUS                             VARCHAR(32 BYTE)                    
IS_DEFAULT                                   BINARY_INTEGER                      
RESOURCE_POOL_ID                             VARCHAR(128 BYTE)                   
PROJECT_ID                                   VARCHAR(128 BYTE)                   
AZ_ID                                        VARCHAR(128 BYTE)                   
EXTEND1                                      VARCHAR(128 BYTE)                   
EXTEND2                                      VARCHAR(128 BYTE)                   
EXTEND3                                      BINARY_INTEGER                      
EXTEND4                                      BINARY_BIGINT                       
PRODUCT_TYPE                                 VARCHAR(32 BYTE)                    
ADD_COL1                                     BINARY_INTEGER                      
ADD_COL2                                     NUMBER                              

SQL> EXP TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_drop_desc.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/add_drop_desc.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_drop_desc.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/add_drop_desc.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)), sum(ADD_COL1), sum(ADD_COL2) from MOPRODUCTDB_T_PRODUCT;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))            SUM(ADD_COL1)        SUM(ADD_COL2)                           
---------------------- ---------------------- ---------------------------------------- -------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                                          58.8085211256065754459588283913204473619

1 rows fetched.

SQL> select ADD_COL1, ADD_COL2 from MOPRODUCTDB_T_PRODUCT limit 1;

ADD_COL1     ADD_COL2                                
------------ ----------------------------------------
             .295520206661339575105320745685027373678

1 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS MOPRODUCTDB_T_PRODUCT_X CASCADE CONSTRAINTS;

Succeed.

SQL> CREATE TABLE MOPRODUCTDB_T_PRODUCT_X AS SELECT * FROM COPY_T_PRODUCT;

Succeed.

SQL> ALTER TABLE MOPRODUCTDB_T_PRODUCT_X ADD (ADD_LOB_COL1 CLOB, ADD_LOB_COL2 CLOB, ADD_LOB_COL3 CLOB);

Succeed.

SQL> 
SQL> EXP USERS=MOPRODUCTDB FILETYPE=BIN file="./moproductdb_dir/moproductdb_usr.sql";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = MOPRODUCTDB
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/moproductdb_usr.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema MOPRODUCTDB ...
Exporting sequence of schema MOPRODUCTDB ...
Exporting profile of schema MOPRODUCTDB ...
Exporting type of schema MOPRODUCTDB ...
Exporting tables of schema MOPRODUCTDB ...
Reading table objects of MOPRODUCTDB

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
COPY_T_PRODUCT                                                   1         
MOPRODUCTDB_T_PRODUCT                                            2         
MOPRODUCTDB_T_PRODUCT_X                                          3         

Exporting tables (scripts or data) of MOPRODUCTDB
exporting table MOPRODUCTDB.COPY_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.COPY_T_PRODUCT ...
  exporting data of MOPRODUCTDB.COPY_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.COPY_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.COPY_T_PRODUCT ...

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT ...

exporting table MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT_X ...
  exporting DDL of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT_X ...
  exporting data of MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT_X ...
    data exporting success, 199 rows are dumped.

  exporting indexes on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT_X ...
  exporting constraints on MOPRODUCTDB.MOPRODUCTDB_T_PRODUCT_X ...

Exporting procedures/functions/triggers of schema MOPRODUCTDB ...
Exporting views of schema MOPRODUCTDB ...
Exporting synonyms of schema MOPRODUCTDB ...
Exporting package of schema MOPRODUCTDB ...
End of export schema MOPRODUCTDB ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS "MOPRODUCTDB_T_PRODUCT" CASCADE CONSTRAINTS;

Succeed.

SQL> IMPORT TABLES=MOPRODUCTDB_T_PRODUCT FILETYPE=BIN file="./moproductdb_dir/add_drop_desc.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MOPRODUCTDB_T_PRODUCT
-- DUMP FILE = ./moproductdb_dir/add_drop_desc.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MOPRODUCTDB_T_PRODUCT                                            199                 

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 199 rows are loaded.
Logical import succeeded.

SQL> 
SQL> desc MOPRODUCTDB_T_PRODUCT_X

Name                                Null?    Type                                
----------------------------------- -------- ------------------------------------
ID                                  NOT NULL VARCHAR(36 BYTE)                    
SERVICE_TYPE                        NOT NULL VARCHAR(32 BYTE)                    
CREATE_VDC_ID                                VARCHAR(64 BYTE)                    
CREATE_USER_ID                               VARCHAR(64 BYTE)                    
ICON_ID                                      VARCHAR(36 BYTE)                    
CATALOG_ID                                   VARCHAR(36 BYTE)                    
REGION_ID                                    VARCHAR(128 BYTE)                   
PARAMS                                       CLOB                                
SECRET_PARAMS                                CLOB                                
NAME                                NOT NULL VARCHAR(8000 BYTE)                  
DESCRIPTION                                  VARCHAR(8000 BYTE)                  
CREATE_TIME                                  DATE                                
PUBLISH_STATUS                               VARCHAR(32 BYTE)                    
DELETABLE_STATUS                             VARCHAR(32 BYTE)                    
IS_DEFAULT                                   BINARY_INTEGER                      
RESOURCE_POOL_ID                             VARCHAR(128 BYTE)                   
PROJECT_ID                                   VARCHAR(128 BYTE)                   
AZ_ID                                        VARCHAR(128 BYTE)                   
EXTEND1                                      VARCHAR(128 BYTE)                   
EXTEND2                                      VARCHAR(128 BYTE)                   
EXTEND3                                      BINARY_INTEGER                      
EXTEND4                                      BINARY_BIGINT                       
PRODUCT_TYPE                                 VARCHAR(32 BYTE)                    
ADD_LOB_COL1                                 CLOB                                
ADD_LOB_COL2                                 CLOB                                
ADD_LOB_COL3                                 CLOB                                

SQL> select count(*), sum(length(id)), sum(lengthb(params)), sum(lengthb(PROJECT_ID)) from MOPRODUCTDB_T_PRODUCT_X;

COUNT(*)             SUM(LENGTH(ID))                          SUM(LENGTHB(PARAMS))                     SUM(LENGTHB(PROJECT_ID))                
-------------------- ---------------------------------------- ---------------------------------------- ----------------------------------------
199                  6353                                     2101421                                                                          

1 rows fetched.

SQL> select max(CREATE_TIME), min(CREATE_TIME), sum(length(DELETABLE_STATUS)) from MOPRODUCTDB_T_PRODUCT_X;

MAX(CREATE_TIME)       MIN(CREATE_TIME)       SUM(LENGTH(DELETABLE_STATUS))           
---------------------- ---------------------- ----------------------------------------
2019-02-21 09:48:27    2019-01-31 22:06:09    1198                                    

1 rows fetched.

SQL> select ADD_LOB_COL1, ADD_LOB_COL2, ADD_LOB_COL3 from MOPRODUCTDB_T_PRODUCT_X limit 1;

ADD_LOB_COL1                                                     ADD_LOB_COL2                                                     ADD_LOB_COL3                                                    
---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
                                                                                                                                                                                                  

1 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS "R_CTRL_OPERATION" CASCADE CONSTRAINTS;

Succeed.

SQL> CREATE TABLE "R_CTRL_OPERATION"
  2 (
  3   "CTRL_ID" VARCHAR(64 CHAR) NOT NULL,
  4   "OPERATION_ID" VARCHAR(64 CHAR) NOT NULL,
  5   PRIMARY KEY("CTRL_ID", "OPERATION_ID")
  6 );

Succeed.

SQL> 
SQL> insert into "R_CTRL_OPERATION" select hex(rownum||rownum||rownum), hex(exp(rownum)) from dual connect by rownum < 100;

99 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> EXP TABLES=R_CTRL_OPERATION FILETYPE=BIN file="./moproductdb_dir/unique_constraint_violated.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = R_CTRL_OPERATION
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/unique_constraint_violated.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.R_CTRL_OPERATION ...
  exporting DDL of MOPRODUCTDB.R_CTRL_OPERATION ...
  exporting data of MOPRODUCTDB.R_CTRL_OPERATION ...
    data exporting success, 99 rows are dumped.

  exporting indexes on MOPRODUCTDB.R_CTRL_OPERATION ...
  exporting constraints on MOPRODUCTDB.R_CTRL_OPERATION ...

Logical export succeeded.

SQL> IMPORT TABLES=R_CTRL_OPERATION FILETYPE=BIN file="./moproductdb_dir/unique_constraint_violated.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = R_CTRL_OPERATION
-- DUMP FILE = ./moproductdb_dir/unique_constraint_violated.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    R_CTRL_OPERATION                                                 99                  

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 99 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(CTRL_ID)), sum(length("OPERATION_ID")) from R_CTRL_OPERATION;

COUNT(*)             SUM(LENGTH(CTRL_ID))                     SUM(LENGTH("OPERATION_ID"))             
-------------------- ---------------------------------------- ----------------------------------------
99                   1134                                     1259                                    

1 rows fetched.

SQL> 
SQL> EXP TABLES=R_CTRL_OPERATION FILETYPE=BIN file="./moproductdb_dir/unique_constraint_violated_02.sql" PARALLEL = 3;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = R_CTRL_OPERATION
-- FILE TYPE = BIN
-- DUMP FILE = ./moproductdb_dir/unique_constraint_violated_02.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 3
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.R_CTRL_OPERATION ...
  exporting DDL of MOPRODUCTDB.R_CTRL_OPERATION ...
    data exporting success! 99 rows are dumped.
  exporting indexes on MOPRODUCTDB.R_CTRL_OPERATION ...
  exporting constraints on MOPRODUCTDB.R_CTRL_OPERATION ...

Logical export succeeded.

SQL> IMPORT TABLES=R_CTRL_OPERATION FILETYPE=BIN file="./moproductdb_dir/unique_constraint_violated_02.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = R_CTRL_OPERATION
-- DUMP FILE = ./moproductdb_dir/unique_constraint_violated_02.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MOPRODUCTDB ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MOPRODUCTDB ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MOPRODUCTDB ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MOPRODUCTDB ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    R_CTRL_OPERATION                                                 99                  

  Importing foreign key of schema MOPRODUCTDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MOPRODUCTDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MOPRODUCTDB ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MOPRODUCTDB ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MOPRODUCTDB ...
    Package importing success, 0 rows are loaded.

data importing success, 99 rows are loaded.
Logical import succeeded.

SQL> 
SQL> select count(*), sum(length(CTRL_ID)), sum(length("OPERATION_ID")) from R_CTRL_OPERATION;

COUNT(*)             SUM(LENGTH(CTRL_ID))                     SUM(LENGTH("OPERATION_ID"))             
-------------------- ---------------------------------------- ----------------------------------------
99                   1134                                     1259                                    

1 rows fetched.

SQL> 
SQL> drop table if exists "你好tb;drop ''table 101";

Succeed.

SQL> create table "你好tb;drop ''table 101" (id int, name varchar(100));

Succeed.

SQL> insert into "你好tb;drop ''table 101" values(1, 'X');

1 rows affected.

SQL> insert into "你好tb;drop ''table 101" values(2, 'x');

1 rows affected.

SQL> insert into "你好tb;drop ''table 101" select id + id, name || name from "你好tb;drop ''table 101";

2 rows affected.

SQL> insert into "你好tb;drop ''table 101" select id + id, name || name from "你好tb;drop ''table 101";

4 rows affected.

SQL> insert into "你好tb;drop ''table 101" select id + id, name || name from "你好tb;drop ''table 101";

8 rows affected.

SQL> SELECT * FROM "你好tb;drop ''table 101" order by id, name;

ID           NAME                                                            
------------ ----------------------------------------------------------------
1            X                                                               
2            XX                                                              
2            XX                                                              
2            XX                                                              
2            x                                                               
4            XXXX                                                            
4            XXXX                                                            
4            XXXX                                                            
4            xx                                                              
4            xx                                                              
4            xx                                                              
8            XXXXXXXX                                                        
8            xxxx                                                            
8            xxxx                                                            
8            xxxx                                                            
16           xxxxxxxx                                                        

16 rows fetched.

SQL> EXP TABLES="你好tb;drop ''table 101" FILE="./moproductdb_dir/sp_table101.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = 你好tb;drop ''table 101
-- FILE TYPE = TXT
-- DUMP FILE = ./moproductdb_dir/sp_table101.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MOPRODUCTDB.你好tb;drop ''table 101 ...
  exporting DDL of MOPRODUCTDB.你好tb;drop ''table 101 ...
  exporting data of MOPRODUCTDB.你好tb;drop ''table 101 ...
    data exporting success, 16 rows are dumped.

  exporting indexes on MOPRODUCTDB.你好tb;drop ''table 101 ...
  exporting constraints on MOPRODUCTDB.你好tb;drop ''table 101 ...

Logical export succeeded.

SQL> 
SQL> IMP TABLES="你好tb;drop ''table 101" FILE="./moproductdb_dir/sp_table101.dmp";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = 你好tb;drop ''table 101
-- DUMP FILE = ./moproductdb_dir/sp_table101.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 16 rows are loaded.
Logical import succeeded.

SQL> desc "你好tb;drop ''table 101"

Name                                Null?    Type                                
----------------------------------- -------- ------------------------------------
ID                                           BINARY_INTEGER                      
NAME                                         VARCHAR(100 BYTE)                   

SQL> SELECT * FROM "你好tb;drop ''table 101" order by id, name;

ID           NAME                                                            
------------ ----------------------------------------------------------------
1            X                                                               
2            XX                                                              
2            XX                                                              
2            XX                                                              
2            x                                                               
4            XXXX                                                            
4            XXXX                                                            
4            XXXX                                                            
4            xx                                                              
4            xx                                                              
4            xx                                                              
8            XXXXXXXX                                                        
8            xxxx                                                            
8            xxxx                                                            
8            xxxx                                                            
16           xxxxxxxx                                                        

16 rows fetched.

SQL> 
SQL> --DTS2019032306861
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists using_index_local;

Succeed.

SQL> create user using_index_local identified by Cantian_234;

Succeed.

SQL> grant dba to using_index_local;

Succeed.

SQL> conn using_index_local/Cantian_234@127.0.0.1:1611

connected.

SQL> drop table if exists T_TESTNODEB;

Succeed.

SQL> create table T_TESTNODEB(
  2     PlanID int,
  3     NodeBID int,
  4     ObjectID int default 0,
  5     PRIMARY KEY(PlanID, NodeBID) using index local
  6 )
  7 PARTITION BY RANGE(PlanID) INTERVAL(1) (PARTITION p_0 VALUES less than(1))
  8 /

Succeed.

SQL> create sequence seq_TESTNODEB
  2 /

Succeed.

SQL> create or replace trigger tr_TESTNODEB
  2     before insert
  3     on T_TESTNODEB
  4     for each row
  5     begin
  6         select seq_TESTNODEB.nextval into :new.ObjectID from dual;
  7     end;
  8 /

Succeed.

SQL> create index idx_t_TestNodeB on t_TestNodeB(PlanID) local
  2 /

Succeed.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> exp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_1.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TESTNODEB
-- FILE TYPE = TXT
-- DUMP FILE = using_index_local_1.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting DDL of USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting data of USING_INDEX_LOCAL.T_TESTNODEB ...
    data exporting success, 0 rows are dumped.

  exporting indexes on USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting constraints on USING_INDEX_LOCAL.T_TESTNODEB ...

Exporting triggers of table T_TESTNODEB ...
  exporting trigger TR_TESTNODEB
Logical export succeeded.

SQL> imp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_1.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TESTNODEB
-- DUMP FILE = using_index_local_1.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> exp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_2.sql" CONSISTENT=Y;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TESTNODEB
-- FILE TYPE = TXT
-- DUMP FILE = using_index_local_2.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = Y
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting DDL of USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting data of USING_INDEX_LOCAL.T_TESTNODEB ...
    data exporting success, 0 rows are dumped.

  exporting indexes on USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting constraints on USING_INDEX_LOCAL.T_TESTNODEB ...

Exporting triggers of table T_TESTNODEB ...
  exporting trigger TR_TESTNODEB
Logical export succeeded.

SQL> imp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_2.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TESTNODEB
-- DUMP FILE = using_index_local_2.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> drop table T_TESTNODEB;

Succeed.

SQL> 
SQL> create table T_TESTNODEB(
  2     PlanID int,
  3     NodeBID int,
  4     ObjectID int default 0
  5 ) PARTITION BY RANGE(PlanID) INTERVAL(1) (PARTITION p_0 VALUES less than(1));

Succeed.

SQL> create index idx_t_TestNodeB on t_TestNodeB(PlanID) local;

Succeed.

SQL> ALTER TABLE T_TESTNODEB ADD CONSTRAINT PK#T_TESTNODEB PRIMARY KEY(PlanID, NodeBID) using index local;

Succeed.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> exp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_3.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TESTNODEB
-- FILE TYPE = TXT
-- DUMP FILE = using_index_local_3.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting DDL of USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting data of USING_INDEX_LOCAL.T_TESTNODEB ...
    data exporting success, 0 rows are dumped.

  exporting indexes on USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting constraints on USING_INDEX_LOCAL.T_TESTNODEB ...

Logical export succeeded.

SQL> imp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_3.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TESTNODEB
-- DUMP FILE = using_index_local_3.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> exp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_4.sql" CONSISTENT=Y;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TESTNODEB
-- FILE TYPE = TXT
-- DUMP FILE = using_index_local_4.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = Y
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting DDL of USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting data of USING_INDEX_LOCAL.T_TESTNODEB ...
    data exporting success, 0 rows are dumped.

  exporting indexes on USING_INDEX_LOCAL.T_TESTNODEB ...
  exporting constraints on USING_INDEX_LOCAL.T_TESTNODEB ...

Logical export succeeded.

SQL> imp FILETYPE=TXT CONTENT=ALL TABLES=T_TESTNODEB FILE="using_index_local_4.sql";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TESTNODEB
-- DUMP FILE = using_index_local_4.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select IS_PRIMARY,PARTITIONED from user_indexes where table_name = 'T_TESTNODEB' order by IS_PRIMARY;

IS_PRIMARY PARTITIONED
---------- -----------
N          Y          
Y          Y          

2 rows fetched.

SQL> drop table T_TESTNODEB;

Succeed.

SQL> 
SQL> --nologging + trigger
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists u_nolog_trig;

Succeed.

SQL> create user u_nolog_trig identified by Cantian_234;

Succeed.

SQL> grant dba to u_nolog_trig;

Succeed.

SQL> conn u_nolog_trig/Cantian_234@127.0.0.1:1611

connected.

SQL> DROP TABLE IF EXISTS t_nolog_trig;

Succeed.

SQL> CREATE TABLE t_nolog_trig (F_INT1 INT, F_INT2 INT, F_CHAR1 CHAR(16), F_DATE DATE);

Succeed.

SQL> INSERT INTO t_nolog_trig VALUES(2,2,'A','2017-12-11 14:08:00');

1 rows affected.

SQL> CREATE OR REPLACE TRIGGER NOLOG_TRIG BEFORE INSERT ON t_nolog_trig
  2    FOR EACH ROW
  3    BEGIN
  4      UPDATE t_nolog_trig SET F_INT1 = 1;
  5    END;
  6    /

Succeed.

SQL> INSERT INTO t_nolog_trig VALUES(2,3,'A','2017-12-11 14:08:00');

1 rows affected.

SQL> SELECT * FROM t_nolog_trig ORDER BY F_INT2;

F_INT1       F_INT2       F_CHAR1          F_DATE                
------------ ------------ ---------------- ----------------------
1            2            A                2017-12-11 14:08:00   
2            3            A                2017-12-11 14:08:00   

2 rows fetched.

SQL> EXP TABLES=t_nolog_trig FILE="t_nolog_trig.sql";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_NOLOG_TRIG
-- FILE TYPE = TXT
-- DUMP FILE = t_nolog_trig.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table U_NOLOG_TRIG.T_NOLOG_TRIG ...
  exporting DDL of U_NOLOG_TRIG.T_NOLOG_TRIG ...
  exporting data of U_NOLOG_TRIG.T_NOLOG_TRIG ...
    data exporting success, 2 rows are dumped.

  exporting indexes on U_NOLOG_TRIG.T_NOLOG_TRIG ...
  exporting constraints on U_NOLOG_TRIG.T_NOLOG_TRIG ...

Exporting triggers of table T_NOLOG_TRIG ...
  exporting trigger NOLOG_TRIG
Logical export succeeded.

SQL> IMP TABLES=t_nolog_trig FILE="t_nolog_trig.sql" NOLOGGING=Y;
Parsing import options ... 
nologging load need to manual check database not in HA mode and parameter _RCY_CHECK_PCN is false.
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_NOLOG_TRIG
-- DUMP FILE = t_nolog_trig.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = Y

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> SELECT * FROM t_nolog_trig ORDER BY F_INT2;

F_INT1       F_INT2       F_CHAR1          F_DATE                
------------ ------------ ---------------- ----------------------
1            2            A                2017-12-11 14:08:00   
2            3            A                2017-12-11 14:08:00   

2 rows fetched.

SQL> 
SQL> --DTS2019022112554
SQL> conn sys/Huawei@123@127.0.0.1:1611			

connected.

SQL> create role exp_role1;

Succeed.

SQL> create role exp_role2;

Succeed.

SQL> drop user if exists exp_lin_test1;

Succeed.

SQL> create user exp_lin_test1 IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant create table to exp_role1;

Succeed.

SQL> grant create session to exp_role1;

Succeed.

SQL> grant create table to exp_role2;

Succeed.

SQL> grant create session to exp_role2;

Succeed.

SQL> grant dba to exp_lin_test1;

Succeed.

SQL> grant exp_role1 to exp_lin_test1;

Succeed.

SQL> grant exp_role2 to exp_lin_test1;

Succeed.

SQL> commit;

Succeed.

SQL> 
SQL> drop user if exists exp_lin_test2;

Succeed.

SQL> create user exp_lin_test2 IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant create table to exp_role1;

Succeed.

SQL> grant create session to exp_role1;

Succeed.

SQL> grant create table to exp_role2;

Succeed.

SQL> grant create session to exp_role2;

Succeed.

SQL> grant dba to exp_lin_test2;

Succeed.

SQL> grant exp_role1 to exp_lin_test2;

Succeed.

SQL> grant exp_role2 to exp_lin_test2;

Succeed.

SQL> commit;

Succeed.

SQL> 
SQL> select count(*) from SYS_ROLES;

COUNT(*)            
--------------------
6                   

1 rows fetched.

SQL> SELECT count(*) FROM ROLE_SYS_PRIVS;

COUNT(*)            
--------------------
111                 

1 rows fetched.

SQL> 
SQL> exp users=exp_lin_test1,exp_lin_test2 create_user=Y grant=Y role=Y filetype = bin file="temp_bin.dmp";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = EXP_LIN_TEST1, EXP_LIN_TEST2
-- FILE TYPE = BIN
-- DUMP FILE = temp_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = Y
-- ROLE = Y
-- GRANT = Y
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting roles  ...
Grant privilege to role ...
Exporting schema EXP_LIN_TEST1 ...
Exporting user definition of schema EXP_LIN_TEST1 ...
Exporting grant role and privilege of schema EXP_LIN_TEST1 ...
Grant privilege to schema EXP_LIN_TEST1 ...
Grant role to schema EXP_LIN_TEST1 ...
Exporting sequence of schema EXP_LIN_TEST1 ...
Exporting profile of schema EXP_LIN_TEST1 ...
Exporting type of schema EXP_LIN_TEST1 ...
Exporting tables of schema EXP_LIN_TEST1 ...
Reading table objects of EXP_LIN_TEST1

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of EXP_LIN_TEST1
Exporting procedures/functions/triggers of schema EXP_LIN_TEST1 ...
Exporting views of schema EXP_LIN_TEST1 ...
Exporting synonyms of schema EXP_LIN_TEST1 ...
Exporting package of schema EXP_LIN_TEST1 ...
End of export schema EXP_LIN_TEST1 ...

Exporting schema EXP_LIN_TEST2 ...
Exporting user definition of schema EXP_LIN_TEST2 ...
Exporting grant role and privilege of schema EXP_LIN_TEST2 ...
Grant privilege to schema EXP_LIN_TEST2 ...
Grant role to schema EXP_LIN_TEST2 ...
Exporting sequence of schema EXP_LIN_TEST2 ...
Exporting profile of schema EXP_LIN_TEST2 ...
Exporting type of schema EXP_LIN_TEST2 ...
Exporting tables of schema EXP_LIN_TEST2 ...
Reading table objects of EXP_LIN_TEST2

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of EXP_LIN_TEST2
Exporting procedures/functions/triggers of schema EXP_LIN_TEST2 ...
Exporting views of schema EXP_LIN_TEST2 ...
Exporting synonyms of schema EXP_LIN_TEST2 ...
Exporting package of schema EXP_LIN_TEST2 ...
End of export schema EXP_LIN_TEST2 ...

Logical export succeeded.

SQL> drop USER if exists exp_lin_test1;

Succeed.

SQL> drop USER if exists exp_lin_test2;

Succeed.

SQL> drop role exp_role1;

Succeed.

SQL> drop role exp_role2;

Succeed.

SQL> 
SQL> imp users=exp_lin_test1,exp_lin_test2 create_user=Y filetype = bin file="temp_bin.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = EXP_LIN_TEST1, EXP_LIN_TEST2
-- DUMP FILE = temp_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema EXP_LIN_TEST1 ... 
  Importing sequence of schema EXP_LIN_TEST1 ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema EXP_LIN_TEST1 ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema EXP_LIN_TEST1 ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema EXP_LIN_TEST1 ,total number : 0 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema EXP_LIN_TEST1 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema EXP_LIN_TEST1 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema EXP_LIN_TEST1 ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema EXP_LIN_TEST1 ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema EXP_LIN_TEST1 ...
    Package importing success, 0 rows are loaded.


Importing schema EXP_LIN_TEST2 ... 
  Importing sequence of schema EXP_LIN_TEST2 ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema EXP_LIN_TEST2 ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema EXP_LIN_TEST2 ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema EXP_LIN_TEST2 ,total number : 0 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema EXP_LIN_TEST2 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema EXP_LIN_TEST2 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema EXP_LIN_TEST2 ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema EXP_LIN_TEST2 ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema EXP_LIN_TEST2 ...
    Package importing success, 0 rows are loaded.

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> conn exp_lin_test1/exp_user123@127.0.0.1:1611

connected.

SQL> conn exp_lin_test2/exp_user123@127.0.0.1:1611

connected.

SQL> conn sys/Huawei@123@127.0.0.1:1611	

connected.

SQL> select count(*) from SYS_ROLES;

COUNT(*)            
--------------------
6                   

1 rows fetched.

SQL> select count(*) from ROLE_SYS_PRIVS;

COUNT(*)            
--------------------
111                 

1 rows fetched.

SQL> drop USER if exists exp_lin_test1;

Succeed.

SQL> drop USER if exists exp_lin_test2;

Succeed.

SQL> drop role exp_role1;

Succeed.

SQL> drop role exp_role2;

Succeed.

SQL> 
SQL> drop user if exists exp_lin_test1;

Succeed.

SQL> create user exp_lin_test1 IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant dba to exp_lin_test1;

Succeed.

SQL> conn exp_lin_test1/exp_user123@127.0.0.1:1611

connected.

SQL> DROP TABLE IF EXISTS LIN_HASH1;

Succeed.

SQL> CREATE TABLE LIN_HASH1
  2 (
  3   COL_NUMBER1 NUMBER,
  4   COL_TIMESTAMP2 TIMESTAMP(6)
  5 );

Succeed.

SQL> CREATE INDEX LIN_INDEX_TEST1 ON LIN_HASH1(TO_CHAR(COL_TIMESTAMP2), UPPER(COL_NUMBER1));

Succeed.

SQL> CREATE INDEX LIN_INDEX_TEST2 ON LIN_HASH1(COL_TIMESTAMP2, UPPER(COL_NUMBER1), COL_NUMBER1);

Succeed.

SQL> CREATE INDEX LIN_INDEX_TEST3 ON LIN_HASH1(COL_TIMESTAMP2, COL_NUMBER1);

Succeed.

SQL> select * from all_indexES  where TABLE_NAME = 'LIN_HASH1' AND OWNER = 'EXP_LIN_TEST1' ORDER BY INDEX_NAME;

OWNER                                                            INDEX_NAME                                                       INDEX_TYPE TABLE_NAME                                                       TABLESPACE_NAME                                                  IS_PRIMARY IS_UNIQUE IS_DUPLICATE PARTITIONED STATUS  INI_TRANS    MAX_TRANS    PCT_FREE     COLUMN_COUNT COLUMNS                                                          BYTES                PAGES                EXTENTS              BLEVEL       LEAF_BLOCKS  EMPTY_LEAF_BLOCKS DISTINCT_KEYS AVG_LEAF_BLOCKS_PER_KEY AVG_DATA_BLOCKS_PER_KEY CLUSTERING_FACTOR NUM_ROWS     SAMPLE_SIZE  LAST_ANALYZED                    SYS_GENERATE         CR_MODE IS_REVERSED
---------------------------------------------------------------- ---------------------------------------------------------------- ---------- ---------------------------------------------------------------- ---------------------------------------------------------------- ---------- --------- ------------ ----------- ------- ------------ ------------ ------------ ------------ ---------------------------------------------------------------- -------------------- -------------------- -------------------- ------------ ------------ ----------------- ------------- ----------------------- ----------------------- ----------------- ------------ ------------ -------------------------------- -------------------- ------- -----------
EXP_LIN_TEST1                                                    LIN_INDEX_TEST1                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            TO_CHAR(COL_TIMESTAMP2), UPPER(COL_NUMBER1)                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST2                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            3            COL_TIMESTAMP2, UPPER(COL_NUMBER1), COL_NUMBER1                  0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST3                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            COL_TIMESTAMP2, COL_NUMBER1                                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          

3 rows fetched.

SQL> exp users=exp_lin_test1 file="func_index.dmp";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = EXP_LIN_TEST1
-- FILE TYPE = TXT
-- DUMP FILE = func_index.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema EXP_LIN_TEST1 ...
Exporting sequence of schema EXP_LIN_TEST1 ...
Exporting profile of schema EXP_LIN_TEST1 ...
Exporting type of schema EXP_LIN_TEST1 ...
Exporting tables of schema EXP_LIN_TEST1 ...
Reading table objects of EXP_LIN_TEST1

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
LIN_HASH1                                                        1         

Exporting tables (scripts or data) of EXP_LIN_TEST1
exporting table EXP_LIN_TEST1.LIN_HASH1 ...
  exporting DDL of EXP_LIN_TEST1.LIN_HASH1 ...
  exporting data of EXP_LIN_TEST1.LIN_HASH1 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on EXP_LIN_TEST1.LIN_HASH1 ...
  exporting constraints on EXP_LIN_TEST1.LIN_HASH1 ...

Exporting procedures/functions/triggers of schema EXP_LIN_TEST1 ...
Exporting views of schema EXP_LIN_TEST1 ...
Exporting synonyms of schema EXP_LIN_TEST1 ...
Exporting package of schema EXP_LIN_TEST1 ...
End of export schema EXP_LIN_TEST1 ...

Logical export succeeded.

SQL> exp users=exp_lin_test1 QUOTE_NAMES = N file="func_index_quote.dmp";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = EXP_LIN_TEST1
-- FILE TYPE = TXT
-- DUMP FILE = func_index_quote.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = N
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema EXP_LIN_TEST1 ...
Exporting sequence of schema EXP_LIN_TEST1 ...
Exporting profile of schema EXP_LIN_TEST1 ...
Exporting type of schema EXP_LIN_TEST1 ...
Exporting tables of schema EXP_LIN_TEST1 ...
Reading table objects of EXP_LIN_TEST1

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
LIN_HASH1                                                        1         

Exporting tables (scripts or data) of EXP_LIN_TEST1
exporting table EXP_LIN_TEST1.LIN_HASH1 ...
  exporting DDL of EXP_LIN_TEST1.LIN_HASH1 ...
  exporting data of EXP_LIN_TEST1.LIN_HASH1 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on EXP_LIN_TEST1.LIN_HASH1 ...
  exporting constraints on EXP_LIN_TEST1.LIN_HASH1 ...

Exporting procedures/functions/triggers of schema EXP_LIN_TEST1 ...
Exporting views of schema EXP_LIN_TEST1 ...
Exporting synonyms of schema EXP_LIN_TEST1 ...
Exporting package of schema EXP_LIN_TEST1 ...
End of export schema EXP_LIN_TEST1 ...

Logical export succeeded.

SQL> 
SQL> DROP TABLE IF EXISTS LIN_HASH1;

Succeed.

SQL> imp users=exp_lin_test1 file="func_index.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = EXP_LIN_TEST1
-- DUMP FILE = func_index.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select * from all_indexES  where TABLE_NAME = 'LIN_HASH1' AND OWNER = 'EXP_LIN_TEST1' ORDER BY INDEX_NAME;

OWNER                                                            INDEX_NAME                                                       INDEX_TYPE TABLE_NAME                                                       TABLESPACE_NAME                                                  IS_PRIMARY IS_UNIQUE IS_DUPLICATE PARTITIONED STATUS  INI_TRANS    MAX_TRANS    PCT_FREE     COLUMN_COUNT COLUMNS                                                          BYTES                PAGES                EXTENTS              BLEVEL       LEAF_BLOCKS  EMPTY_LEAF_BLOCKS DISTINCT_KEYS AVG_LEAF_BLOCKS_PER_KEY AVG_DATA_BLOCKS_PER_KEY CLUSTERING_FACTOR NUM_ROWS     SAMPLE_SIZE  LAST_ANALYZED                    SYS_GENERATE         CR_MODE IS_REVERSED
---------------------------------------------------------------- ---------------------------------------------------------------- ---------- ---------------------------------------------------------------- ---------------------------------------------------------------- ---------- --------- ------------ ----------- ------- ------------ ------------ ------------ ------------ ---------------------------------------------------------------- -------------------- -------------------- -------------------- ------------ ------------ ----------------- ------------- ----------------------- ----------------------- ----------------- ------------ ------------ -------------------------------- -------------------- ------- -----------
EXP_LIN_TEST1                                                    LIN_INDEX_TEST1                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            TO_CHAR(COL_TIMESTAMP2), UPPER(COL_NUMBER1)                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST2                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            3            COL_TIMESTAMP2, UPPER(COL_NUMBER1), COL_NUMBER1                  0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST3                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            COL_TIMESTAMP2, COL_NUMBER1                                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          

3 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS LIN_HASH1;

Succeed.

SQL> imp users=exp_lin_test1 file="func_index_quote.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = EXP_LIN_TEST1
-- DUMP FILE = func_index_quote.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select * from all_indexES  where TABLE_NAME = 'LIN_HASH1' AND OWNER = 'EXP_LIN_TEST1' ORDER BY INDEX_NAME;

OWNER                                                            INDEX_NAME                                                       INDEX_TYPE TABLE_NAME                                                       TABLESPACE_NAME                                                  IS_PRIMARY IS_UNIQUE IS_DUPLICATE PARTITIONED STATUS  INI_TRANS    MAX_TRANS    PCT_FREE     COLUMN_COUNT COLUMNS                                                          BYTES                PAGES                EXTENTS              BLEVEL       LEAF_BLOCKS  EMPTY_LEAF_BLOCKS DISTINCT_KEYS AVG_LEAF_BLOCKS_PER_KEY AVG_DATA_BLOCKS_PER_KEY CLUSTERING_FACTOR NUM_ROWS     SAMPLE_SIZE  LAST_ANALYZED                    SYS_GENERATE         CR_MODE IS_REVERSED
---------------------------------------------------------------- ---------------------------------------------------------------- ---------- ---------------------------------------------------------------- ---------------------------------------------------------------- ---------- --------- ------------ ----------- ------- ------------ ------------ ------------ ------------ ---------------------------------------------------------------- -------------------- -------------------- -------------------- ------------ ------------ ----------------- ------------- ----------------------- ----------------------- ----------------- ------------ ------------ -------------------------------- -------------------- ------- -----------
EXP_LIN_TEST1                                                    LIN_INDEX_TEST1                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            TO_CHAR(COL_TIMESTAMP2), UPPER(COL_NUMBER1)                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST2                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            3            COL_TIMESTAMP2, UPPER(COL_NUMBER1), COL_NUMBER1                  0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          
EXP_LIN_TEST1                                                    LIN_INDEX_TEST3                                                  NORMAL     LIN_HASH1                                                        USERS                                                            N          N         N            N           VALID   2            255          8            2            COL_TIMESTAMP2, COL_NUMBER1                                      0                    0                    0                                                                                                                                                                                                           0                    PAGE    N          

3 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS LIN_HASH1;

Succeed.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> 
SQL> --DTS2019032506534
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> DROP USER IF EXISTS test_schema;

Succeed.

SQL> create user test_schema identified by Cantian_234;

Succeed.

SQL> DROP TABLE IF EXISTS curr_schema;

Succeed.

SQL> create table test_schema.curr_schema as select * from dual;

Succeed.

SQL> EXP USERS = test_schema FILE="test_schema.dmp" filetype = txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TEST_SCHEMA
-- FILE TYPE = TXT
-- DUMP FILE = test_schema.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TEST_SCHEMA ...
Exporting sequence of schema TEST_SCHEMA ...
Exporting profile of schema TEST_SCHEMA ...
Exporting type of schema TEST_SCHEMA ...
Exporting tables of schema TEST_SCHEMA ...
Reading table objects of TEST_SCHEMA

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
CURR_SCHEMA                                                      1         

Exporting tables (scripts or data) of TEST_SCHEMA
exporting table TEST_SCHEMA.CURR_SCHEMA ...
  exporting DDL of TEST_SCHEMA.CURR_SCHEMA ...
  exporting data of TEST_SCHEMA.CURR_SCHEMA ...
    data exporting success, 1 rows are dumped.

  exporting indexes on TEST_SCHEMA.CURR_SCHEMA ...
  exporting constraints on TEST_SCHEMA.CURR_SCHEMA ...

Exporting procedures/functions/triggers of schema TEST_SCHEMA ...
Exporting views of schema TEST_SCHEMA ...
Exporting synonyms of schema TEST_SCHEMA ...
Exporting package of schema TEST_SCHEMA ...
End of export schema TEST_SCHEMA ...

Logical export succeeded.

SQL> IMP USERS = test_schema FILE="test_schema.dmp" filetype = txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = TEST_SCHEMA
-- DUMP FILE = test_schema.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 1 rows are loaded.
Logical import succeeded.

SQL> select USER_NAME,CURR_SCHEMA  from V$ME;

USER_NAME                                                        CURR_SCHEMA                                                     
---------------------------------------------------------------- ----------------------------------------------------------------
SYS                                                              SYS                                                             

1 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists tbl_trigger;

Succeed.

SQL> create user tbl_trigger identified by Cantian_234;

Succeed.

SQL> grant dba to tbl_trigger;

Succeed.

SQL> conn tbl_trigger/Cantian_234@127.0.0.1:1611

connected.

SQL> drop table if exists T_TESTNODEB;

Succeed.

SQL> create table T_TESTNODEB(
  2     PlanID int,
  3     NodeBID int,
  4     ObjectID int default 0,
  5     PRIMARY KEY(PlanID, NodeBID) using index local
  6 )
  7 PARTITION BY RANGE(PlanID) INTERVAL(1) (PARTITION p_0 VALUES less than(1));

Succeed.

SQL> 
SQL> create sequence seq_TESTNODEB;

Succeed.

SQL> 
SQL> create or replace trigger tr_TESTNODEB
  2     before insert
  3     on T_TESTNODEB
  4     for each row
  5     begin
  6         select seq_TESTNODEB.nextval into :new.ObjectID from dual;
  7     end;
  8 /

Succeed.

SQL> 
SQL> create index idx_t_TestNodeB on t_TestNodeB(PlanID) local;

Succeed.

SQL> 
SQL> insert into T_TESTNODEB(PlanID, NodeBID) values(1,1);

1 rows affected.

SQL> insert into T_TESTNODEB(PlanID, NodeBID) values(2,1);

1 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> drop table if exists T_TEST2;

Succeed.

SQL> create table T_TEST2(
  2     PlanID int,
  3     NodeBID int,
  4     ObjectID int default 0,
  5     PRIMARY KEY(PlanID, NodeBID) using index local
  6 )
  7 PARTITION BY RANGE(PlanID) INTERVAL(1) (PARTITION p_0 VALUES less than(1));

Succeed.

SQL> 
SQL> create or replace trigger tr_TEST
  2     before insert
  3     on T_TEST2
  4     for each row
  5     begin
  6         select seq_TESTNODEB.nextval into :new.ObjectID from dual;
  7     end;
  8 /

Succeed.

SQL> 
SQL> insert into T_TEST2(PlanID, NodeBID) values(1,1);

1 rows affected.

SQL> insert into T_TEST2(PlanID, NodeBID) values(2,1);

1 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> conn tbl_trigger/Cantian_234@127.0.0.1:1611

connected.

SQL> exp tables=T_TEST2 file="trigger_bin.dat" filetype=bin;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TEST2
-- FILE TYPE = BIN
-- DUMP FILE = trigger_bin.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of table T_TEST2 ...
  exporting trigger TR_TEST
Logical export succeeded.

SQL> exp tables=T_TEST2 file="trigger_bin_p.dat" filetype=bin parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TEST2
-- FILE TYPE = BIN
-- DUMP FILE = trigger_bin_p.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
    data exporting success! 2 rows are dumped.
  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of table T_TEST2 ...
  exporting trigger TR_TEST
Logical export succeeded.

SQL> exp tables=% file="all_trigger_bin.dat" filetype=bin;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = ALL_TABLES
-- EXPORT OBJECTS = 
-- FILE TYPE = BIN
-- DUMP FILE = all_trigger_bin.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
  exporting data of TBL_TRIGGER.T_TESTNODEB ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Logical export succeeded.

SQL> exp tables=% file="all_trigger_bin_p.dat" filetype=bin parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = ALL_TABLES
-- EXPORT OBJECTS = 
-- FILE TYPE = BIN
-- DUMP FILE = all_trigger_bin_p.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
    data exporting success! 2 rows are dumped.
  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
    data exporting success! 2 rows are dumped.
  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Logical export succeeded.

SQL> 
SQL> exp tables=T_TEST2 file="trigger_txt.dat" filetype=txt;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TEST2
-- FILE TYPE = TXT
-- DUMP FILE = trigger_txt.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of table T_TEST2 ...
  exporting trigger TR_TEST
Logical export succeeded.

SQL> exp tables=T_TEST2 file="trigger_txt_p.dat" filetype=txt parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = T_TEST2
-- FILE TYPE = TXT
-- DUMP FILE = trigger_txt_p.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of table T_TEST2 ...
  exporting trigger TR_TEST
Logical export succeeded.

SQL> exp tables=% file="all_trigger_txt.dat" filetype=txt;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = ALL_TABLES
-- EXPORT OBJECTS = 
-- FILE TYPE = TXT
-- DUMP FILE = all_trigger_txt.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
  exporting data of TBL_TRIGGER.T_TESTNODEB ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Logical export succeeded.

SQL> exp tables=% file="all_trigger_txt_p.dat" filetype=txt parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = ALL_TABLES
-- EXPORT OBJECTS = 
-- FILE TYPE = TXT
-- DUMP FILE = all_trigger_txt_p.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Logical export succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> exp users=tbl_trigger file="user_trigger_bin.dat" filetype=bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TBL_TRIGGER
-- FILE TYPE = BIN
-- DUMP FILE = user_trigger_bin.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TBL_TRIGGER ...
Exporting sequence of schema TBL_TRIGGER ...
Exporting profile of schema TBL_TRIGGER ...
Exporting type of schema TBL_TRIGGER ...
Exporting tables of schema TBL_TRIGGER ...
Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
  exporting data of TBL_TRIGGER.T_TESTNODEB ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting procedures/functions/triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Exporting views of schema TBL_TRIGGER ...
Exporting synonyms of schema TBL_TRIGGER ...
Exporting package of schema TBL_TRIGGER ...
End of export schema TBL_TRIGGER ...

Logical export succeeded.

SQL> exp users=tbl_trigger file="user_trigger_txt.dat" filetype=txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TBL_TRIGGER
-- FILE TYPE = TXT
-- DUMP FILE = user_trigger_txt.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TBL_TRIGGER ...
Exporting sequence of schema TBL_TRIGGER ...
Exporting profile of schema TBL_TRIGGER ...
Exporting type of schema TBL_TRIGGER ...
Exporting tables of schema TBL_TRIGGER ...
Reading table objects of TBL_TRIGGER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T_TESTNODEB                                                      1         
T_TEST2                                                          2         

Exporting tables (scripts or data) of TBL_TRIGGER
exporting table TBL_TRIGGER.T_TESTNODEB ...
  exporting DDL of TBL_TRIGGER.T_TESTNODEB ...
  exporting data of TBL_TRIGGER.T_TESTNODEB ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TESTNODEB ...
  exporting constraints on TBL_TRIGGER.T_TESTNODEB ...

exporting table TBL_TRIGGER.T_TEST2 ...
  exporting DDL of TBL_TRIGGER.T_TEST2 ...
  exporting data of TBL_TRIGGER.T_TEST2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TBL_TRIGGER.T_TEST2 ...
  exporting constraints on TBL_TRIGGER.T_TEST2 ...

Exporting procedures/functions/triggers of schema TBL_TRIGGER ...
  exporting TRIGGER TBL_TRIGGER.TR_TESTNODEB
  exporting TRIGGER TBL_TRIGGER.TR_TEST
Exporting views of schema TBL_TRIGGER ...
Exporting synonyms of schema TBL_TRIGGER ...
Exporting package of schema TBL_TRIGGER ...
End of export schema TBL_TRIGGER ...

Logical export succeeded.

SQL> 
SQL> conn tbl_trigger/Cantian_234@127.0.0.1:1611

connected.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="trigger_bin.dat" filetype=bin;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = trigger_bin.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

1 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="trigger_bin_p.dat" filetype=bin parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = trigger_bin_p.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

1 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=% file="all_trigger_bin.dat" filetype=bin;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = all_trigger_bin.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TESTNODEB                                                      2                   
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 2 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=% file="all_trigger_bin_p.dat" filetype=bin parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = all_trigger_bin_p.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TESTNODEB                                                      2                   
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 2 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="trigger_txt.dat" filetype=txt;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = trigger_txt.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

1 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="trigger_txt_p.dat" filetype=txt parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = trigger_txt_p.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

1 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=% file="all_trigger_txt.dat" filetype=txt;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = all_trigger_txt.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=% file="all_trigger_txt_p.dat" filetype=txt parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = all_trigger_txt_p.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="all_trigger_txt.dat" filetype=txt;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = all_trigger_txt.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="all_trigger_bin.dat" filetype=bin;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = all_trigger_bin.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

1 rows fetched.

SQL> 
SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> conn tbl_trigger/Cantian_234@127.0.0.1:1611

connected.

SQL> imp tables=% file="user_trigger_bin.dat" filetype=bin;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = user_trigger_bin.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema TBL_TRIGGER ... 
  Importing sequence of schema TBL_TRIGGER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TBL_TRIGGER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TBL_TRIGGER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TBL_TRIGGER ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TESTNODEB                                                      2                   
    T_TEST2                                                          2                   

  Importing foreign key of schema TBL_TRIGGER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TBL_TRIGGER ...
    Fuction/procedure/trigger importing success, 2 rows are loaded.

  Importing view of schema TBL_TRIGGER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TBL_TRIGGER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TBL_TRIGGER ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> drop trigger if exists tr_TESTNODEB;

Succeed.

SQL> drop trigger if exists tr_TEST;

Succeed.

SQL> imp tables=T_TEST2 file="user_trigger_txt.dat" filetype=txt;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = T_TEST2
-- DUMP FILE = user_trigger_txt.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select OWNER,TRIGGER_NAME,TABLE_OWNER,TABLE_OWNER from all_triggers where owner = 'TBL_TRIGGER';

OWNER                                                            TRIGGER_NAME                                                     TABLE_OWNER                                                      TABLE_OWNER                                                     
---------------------------------------------------------------- ---------------------------------------------------------------- ---------------------------------------------------------------- ----------------------------------------------------------------
TBL_TRIGGER                                                      TR_TESTNODEB                                                     TBL_TRIGGER                                                      TBL_TRIGGER                                                     
TBL_TRIGGER                                                      TR_TEST                                                          TBL_TRIGGER                                                      TBL_TRIGGER                                                     

2 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists verify_user;

Succeed.

SQL> create user verify_user IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant dba to verify_user;

Succeed.

SQL> conn verify_user/exp_user123@127.0.0.1:1611

connected.

SQL> drop table if exists test_lin;

Succeed.

SQL> create table test_lin(f1 int, f2 int, f3 int);

Succeed.

SQL> exp tables=test_lin filetype=bin file = "verify_opts.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TEST_LIN
-- FILE TYPE = BIN
-- DUMP FILE = verify_opts.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table VERIFY_USER.TEST_LIN ...
  exporting DDL of VERIFY_USER.TEST_LIN ...
  exporting data of VERIFY_USER.TEST_LIN ...
    data exporting success, 0 rows are dumped.

  exporting indexes on VERIFY_USER.TEST_LIN ...
  exporting constraints on VERIFY_USER.TEST_LIN ...

Logical export succeeded.

SQL> imp tables=test_lin filetype=bin file = "verify_opts_thread.dmp" parallel=33;
Parsing import options ... 
Verify options ...

CT-00601, Sql syntax error: threads should be in [1, 32]
Logical import failed.

SQL> imp tables=test_lin filetype=bin file = "verify_opts_thread.dmp" ddl_parallel=0;
Parsing import options ... 
Verify options ...

CT-00601, Sql syntax error: threads should be in [1, 32]
Logical import failed.

SQL> imp tables=t2 filetype=bin file = "verify_opts.dmp" BATCH_COUNT=10001;
Parsing import options ... 
Verify options ...

CT-00601, Sql syntax error: BATCH_COUNT should be in [1, 10000]
Logical import failed.

SQL> drop table if exists test_lin;

Succeed.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists imp_manul;

Succeed.

SQL> create user imp_manul IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant dba to imp_manul;

Succeed.

SQL> conn imp_manul/exp_user123@127.0.0.1:1611

connected.

SQL> imp users=imp_manul file="./data/imp_manul_append_data.bat";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = IMP_MANUL
-- DUMP FILE = ./data/imp_manul_append_data.bat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> imp users=AUDITLOGDB filetype=bin ignore=y content=data_only create_user=y parallel=32 file="./data/compatible_data/spc100/compatible_bin_data_only/data_bin_single_user_01.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = AUDITLOGDB
-- DUMP FILE = ./data/compatible_data/spc100/compatible_bin_data_only/data_bin_single_user_01.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 32
-- DDL_PARALLEL = 1
-- CONTENT_MODE = DATA_ONLY
-- IGNORE = Y
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema ADMINHOMEDB ... 
  Importing sequence of schema ADMINHOMEDB ...
    Sequence importing success, 0 rows are loaded.

  Importing tables of schema ADMINHOMEDB ,total number : 19 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema ADMINHOMEDB ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema ADMINHOMEDB ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema ADMINHOMEDB ...
    View importing success, 0 rows are loaded.

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> drop user if exists partition_table_exp;

Succeed.

SQL> create user partition_table_exp IDENTIFIED by 'exp_user123';

Succeed.

SQL> grant dba to partition_table_exp;

Succeed.

SQL> conn partition_table_exp/exp_user123@127.0.0.1:1611

connected.

SQL> CREATE TABLE TEST
  2 (
  3 PLANID BINARY_INTEGER NOT NULL AUTO_INCREMENT,
  4 NODEBID BINARY_INTEGER NOT NULL,
  5 PRIMARY KEY(PLANID, NODEBID)
  6 )
  7 PARTITION BY RANGE ("NODEBID")
  8 INTERVAL(5)
  9 (
 10 PARTITION P_0 VALUES LESS THAN (5)  INITRANS 2 PCTFREE 8,
 11 PARTITION P_1 VALUES LESS THAN (10)  INITRANS 2 PCTFREE 8
 12 )
 13 INITRANS 2
 14 MAXTRANS 255
 15 PCTFREE 8;

Succeed.

SQL> INSERT INTO "TEST" ("PLANID","NODEBID") values(0,1);

1 rows affected.

SQL> INSERT INTO "TEST" ("PLANID","NODEBID") values(0,4);

1 rows affected.

SQL> INSERT INTO "TEST" ("PLANID","NODEBID") values(0,5);

1 rows affected.

SQL> INSERT INTO "TEST" ("PLANID","NODEBID") values(0,9);

1 rows affected.

SQL> INSERT INTO "TEST" ("PLANID","NODEBID") values(0,10);

1 rows affected.

SQL> commit;

Succeed.

SQL> select * from test order by NODEBID;

PLANID       NODEBID     
------------ ------------
1            1           
2            4           
3            5           
4            9           
5            10          

5 rows fetched.

SQL> exp tables = test file = "./data/partition_table_exp_bin.dmp" filetype=bin parallel=5;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TEST
-- FILE TYPE = BIN
-- DUMP FILE = ./data/partition_table_exp_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 5
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_TABLE_EXP.TEST ...
  exporting DDL of PARTITION_TABLE_EXP.TEST ...
    data exporting success! 5 rows are dumped.
  exporting auto_increment attr on PARTITION_TABLE_EXP.TEST ...
  exporting indexes on PARTITION_TABLE_EXP.TEST ...
  exporting constraints on PARTITION_TABLE_EXP.TEST ...

Logical export succeeded.

SQL> imp tables = test file = "./data/partition_table_exp_bin.dmp" filetype=bin parallel=5;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TEST
-- DUMP FILE = ./data/partition_table_exp_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 5
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema PARTITION_TABLE_EXP ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema PARTITION_TABLE_EXP ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema PARTITION_TABLE_EXP ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema PARTITION_TABLE_EXP ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TEST                                                             5                   

  Importing foreign key of schema PARTITION_TABLE_EXP ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema PARTITION_TABLE_EXP ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema PARTITION_TABLE_EXP ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema PARTITION_TABLE_EXP ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema PARTITION_TABLE_EXP ...
    Package importing success, 0 rows are loaded.

data importing success, 5 rows are loaded.
Logical import succeeded.

SQL> exp tables = test file = "./data/partition_table_exp_txt.dmp" filetype=txt parallel=5;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TEST
-- FILE TYPE = TXT
-- DUMP FILE = ./data/partition_table_exp_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 5
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_TABLE_EXP.TEST ...
  exporting DDL of PARTITION_TABLE_EXP.TEST ...
  exporting auto_increment attr on PARTITION_TABLE_EXP.TEST ...
  exporting indexes on PARTITION_TABLE_EXP.TEST ...
  exporting constraints on PARTITION_TABLE_EXP.TEST ...

Logical export succeeded.

SQL> imp tables = test file = "./data/partition_table_exp_txt.dmp" filetype=txt parallel=5;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TEST
-- DUMP FILE = ./data/partition_table_exp_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 5
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists import_verify_table;

Succeed.

SQL> create user import_verify_table IDENTIFIED by 'imp_user123';

Succeed.

SQL> grant dba to import_verify_table;

Succeed.

SQL> conn import_verify_table/imp_user123@127.0.0.1:1611

connected.

SQL> --DTS2019121603646
SQL> IMP TABLES=training233 FILETYPE=txt CONTENT=data_only PARALLEL=10 FILE="test1.sql";
Parsing import options ... 
Verify options ...
  verify tables ...

CT-00708, The object table TRAINING233 does not exist
Logical import failed.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> 
SQL> -- test metadata comment export & import
SQL> drop user if exists exp_imp_comment;

Succeed.

SQL> create user exp_imp_comment identified by Test_123456;

Succeed.

SQL> grant dba to exp_imp_comment;

Succeed.

SQL> conn exp_imp_comment/Test_123456@127.0.0.1:1611

connected.

SQL> create table ts(c int);

Succeed.

SQL> insert into ts values(1);

1 rows affected.

SQL> commit;

Succeed.

SQL> exp tables=ts file="./data/exp_imp_comment_txt.dmp" filetype=txt content=metadata_only;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TS
-- FILE TYPE = TXT
-- DUMP FILE = ./data/exp_imp_comment_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = METADATA_ONLY
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table EXP_IMP_COMMENT.TS ...
  exporting DDL of EXP_IMP_COMMENT.TS ...

  exporting indexes on EXP_IMP_COMMENT.TS ...
  exporting constraints on EXP_IMP_COMMENT.TS ...

Logical export succeeded.

SQL> exp tables=ts file="./data/exp_imp_comment_bin.dmp" filetype=bin content=metadata_only;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TS
-- FILE TYPE = BIN
-- DUMP FILE = ./data/exp_imp_comment_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = METADATA_ONLY
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table EXP_IMP_COMMENT.TS ...
  exporting DDL of EXP_IMP_COMMENT.TS ...

  exporting indexes on EXP_IMP_COMMENT.TS ...
  exporting constraints on EXP_IMP_COMMENT.TS ...

Logical export succeeded.

SQL> drop table ts;

Succeed.

SQL> imp tables=ts file="./data/exp_imp_comment_txt.dmp" filetype=txt content=metadata_only;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TS
-- DUMP FILE = ./data/exp_imp_comment_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = METADATA_ONLY
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select * from ts;

C           
------------

0 rows fetched.

SQL> drop table ts;

Succeed.

SQL> imp tables=ts file="./data/exp_imp_comment_bin.dmp" filetype=bin content=metadata_only;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TS
-- DUMP FILE = ./data/exp_imp_comment_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = METADATA_ONLY
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema EXP_IMP_COMMENT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema EXP_IMP_COMMENT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema EXP_IMP_COMMENT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema EXP_IMP_COMMENT ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema EXP_IMP_COMMENT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema EXP_IMP_COMMENT ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema EXP_IMP_COMMENT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema EXP_IMP_COMMENT ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema EXP_IMP_COMMENT ...
    Package importing success, 0 rows are loaded.

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select * from ts;

C           
------------

0 rows fetched.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user exp_imp_comment cascade;

Succeed.

SQL> 
SQL> -- test view dependent of different users
SQL> drop user if exists view_depend;

Succeed.

SQL> create user view_depend identified by Test_123456;

Succeed.

SQL> grant dba to view_depend;

Succeed.

SQL> conn view_depend/Test_123456@127.0.0.1:1611

connected.

SQL> create view v_trans as select * from sys.dv_transactions;

Succeed.

SQL> create view v_trans1 as select * from v_trans;

Succeed.

SQL> exp users=view_depend file="./data/view_depend.dmp";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = VIEW_DEPEND
-- FILE TYPE = TXT
-- DUMP FILE = ./data/view_depend.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema VIEW_DEPEND ...
Exporting sequence of schema VIEW_DEPEND ...
Exporting profile of schema VIEW_DEPEND ...
Exporting type of schema VIEW_DEPEND ...
Exporting tables of schema VIEW_DEPEND ...
Reading table objects of VIEW_DEPEND

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of VIEW_DEPEND
Exporting procedures/functions/triggers of schema VIEW_DEPEND ...
Exporting views of schema VIEW_DEPEND ...
  exporting view VIEW_DEPEND.V_TRANS
  exporting view VIEW_DEPEND.V_TRANS1
Exporting synonyms of schema VIEW_DEPEND ...
Exporting package of schema VIEW_DEPEND ...
End of export schema VIEW_DEPEND ...

Logical export succeeded.

SQL> imp users=view_depend file="./data/view_depend.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = VIEW_DEPEND
-- DUMP FILE = ./data/view_depend.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user view_depend cascade;

Succeed.

SQL> 
SQL> -- DTS2020022730952
SQL> -- test independent role export
SQL> drop user if exists independ_role_exp;

Succeed.

SQL> create user independ_role_exp identified by Test_123456;

Succeed.

SQL> grant dba to independ_role_exp;

Succeed.

SQL> conn independ_role_exp/Test_123456@127.0.0.1:1611

connected.

SQL> create role role_independ_role_exp;

Succeed.

SQL> select count(1) from SYS.SYS_ROLES where name = upper('role_independ_role_exp');

COUNT(1)            
--------------------
1                   

1 rows fetched.

SQL> exp users=independ_role_exp file="./data/independ_role_exp.dmp" role=Y;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = INDEPEND_ROLE_EXP
-- FILE TYPE = TXT
-- DUMP FILE = ./data/independ_role_exp.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = Y
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting roles  ...
Grant privilege to role ...
Exporting schema INDEPEND_ROLE_EXP ...
Exporting sequence of schema INDEPEND_ROLE_EXP ...
Exporting profile of schema INDEPEND_ROLE_EXP ...
Exporting type of schema INDEPEND_ROLE_EXP ...
Exporting tables of schema INDEPEND_ROLE_EXP ...
Reading table objects of INDEPEND_ROLE_EXP

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of INDEPEND_ROLE_EXP
Exporting procedures/functions/triggers of schema INDEPEND_ROLE_EXP ...
Exporting views of schema INDEPEND_ROLE_EXP ...
Exporting synonyms of schema INDEPEND_ROLE_EXP ...
Exporting package of schema INDEPEND_ROLE_EXP ...
End of export schema INDEPEND_ROLE_EXP ...

Logical export succeeded.

SQL> drop role role_independ_role_exp;

Succeed.

SQL> imp users=independ_role_exp file="./data/independ_role_exp.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = INDEPEND_ROLE_EXP
-- DUMP FILE = ./data/independ_role_exp.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> select count(1) from SYS.SYS_ROLES where name = upper('role_independ_role_exp');

COUNT(1)            
--------------------
1                   

1 rows fetched.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user independ_role_exp cascade;

Succeed.

SQL> 
SQL> -- test synonym export
SQL> drop user if exists synonym_export;

Succeed.

SQL> create user synonym_export identified by Test_123456;

Succeed.

SQL> grant dba to synonym_export;

Succeed.

SQL> conn synonym_export/Test_123456@127.0.0.1:1611

connected.

SQL> create table t1(c int);

Succeed.

SQL> insert into t1 values(10086);

1 rows affected.

SQL> create synonym st1 for t1;

Succeed.

SQL> select * from st1;

C           
------------
10086       

1 rows fetched.

SQL> exp users=synonym_export file="./data/synonym_export_txt.dmp" filetype=txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = SYNONYM_EXPORT
-- FILE TYPE = TXT
-- DUMP FILE = ./data/synonym_export_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema SYNONYM_EXPORT ...
Exporting sequence of schema SYNONYM_EXPORT ...
Exporting profile of schema SYNONYM_EXPORT ...
Exporting type of schema SYNONYM_EXPORT ...
Exporting tables of schema SYNONYM_EXPORT ...
Reading table objects of SYNONYM_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T1                                                               1         

Exporting tables (scripts or data) of SYNONYM_EXPORT
exporting table SYNONYM_EXPORT.T1 ...
  exporting DDL of SYNONYM_EXPORT.T1 ...
  exporting data of SYNONYM_EXPORT.T1 ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SYNONYM_EXPORT.T1 ...
  exporting constraints on SYNONYM_EXPORT.T1 ...

Exporting procedures/functions/triggers of schema SYNONYM_EXPORT ...
Exporting views of schema SYNONYM_EXPORT ...
Exporting synonyms of schema SYNONYM_EXPORT ...
Exporting package of schema SYNONYM_EXPORT ...
End of export schema SYNONYM_EXPORT ...

Logical export succeeded.

SQL> drop synonym st1;

Succeed.

SQL> imp users=synonym_export file="./data/synonym_export_txt.dmp" filetype=txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = SYNONYM_EXPORT
-- DUMP FILE = ./data/synonym_export_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 1 rows are loaded.
Logical import succeeded.

SQL> select * from st1;

C           
------------
10086       

1 rows fetched.

SQL> exp users=synonym_export file="./data/synonym_export_bin.dmp" filetype=bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = SYNONYM_EXPORT
-- FILE TYPE = BIN
-- DUMP FILE = ./data/synonym_export_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema SYNONYM_EXPORT ...
Exporting sequence of schema SYNONYM_EXPORT ...
Exporting profile of schema SYNONYM_EXPORT ...
Exporting type of schema SYNONYM_EXPORT ...
Exporting tables of schema SYNONYM_EXPORT ...
Reading table objects of SYNONYM_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
T1                                                               1         

Exporting tables (scripts or data) of SYNONYM_EXPORT
exporting table SYNONYM_EXPORT.T1 ...
  exporting DDL of SYNONYM_EXPORT.T1 ...
  exporting data of SYNONYM_EXPORT.T1 ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SYNONYM_EXPORT.T1 ...
  exporting constraints on SYNONYM_EXPORT.T1 ...

Exporting procedures/functions/triggers of schema SYNONYM_EXPORT ...
Exporting views of schema SYNONYM_EXPORT ...
Exporting synonyms of schema SYNONYM_EXPORT ...
Exporting package of schema SYNONYM_EXPORT ...
End of export schema SYNONYM_EXPORT ...

Logical export succeeded.

SQL> drop synonym st1;

Succeed.

SQL> imp users=synonym_export file="./data/synonym_export_bin.dmp" filetype=bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = SYNONYM_EXPORT
-- DUMP FILE = ./data/synonym_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema SYNONYM_EXPORT ... 
  Importing sequence of schema SYNONYM_EXPORT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema SYNONYM_EXPORT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema SYNONYM_EXPORT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema SYNONYM_EXPORT ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T1                                                               1                   

  Importing foreign key of schema SYNONYM_EXPORT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema SYNONYM_EXPORT ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema SYNONYM_EXPORT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema SYNONYM_EXPORT ...
    Synonym importing success, 1 rows are loaded.

  Importing package of schema SYNONYM_EXPORT ...
    Package importing success, 0 rows are loaded.

data importing success, 1 rows are loaded.
Logical import succeeded.

SQL> select * from st1;

C           
------------
10086       

1 rows fetched.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user synonym_export cascade;

Succeed.

SQL> 
SQL> --- test profile export ---
SQL> CREATE or replace PROFILE test_profile LIMIT PASSWORD_GRACE_TIME 10 PASSWORD_LOCK_TIME DEFAULT PASSWORD_LIFE_TIME UNLIMITED;

Succeed.

SQL> drop user if exists profile_export CASCADE;

Succeed.

SQL> create user profile_export identified by Changeme_123 PROFILE test_profile;

Succeed.

SQL> grant dba to profile_export;

Succeed.

SQL> conn profile_export/Changeme_123@127.0.0.1:1611

connected.

SQL> CREATE PROFILE test_profile2 LIMIT PASSWORD_GRACE_TIME 11 PASSWORD_LOCK_TIME DEFAULT PASSWORD_LIFE_TIME UNLIMITED
  2 /

Succeed.

SQL> CREATE or replace PROFILE test_profile2 LIMIT PASSWORD_GRACE_TIME 11 PASSWORD_LOCK_TIME DEFAULT PASSWORD_LIFE_TIME UNLIMITED
  2 /

Succeed.

SQL> CREATE or replace PROFILE test_profile3 LIMIT PASSWORD_GRACE_TIME 12 PASSWORD_LOCK_TIME DEFAULT PASSWORD_LIFE_TIME UNLIMITED
  2 /

Succeed.

SQL> 
SQL> exp users=profile_export file="./data/profile_export_txt.dmp" filetype = txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = PROFILE_EXPORT
-- FILE TYPE = TXT
-- DUMP FILE = ./data/profile_export_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema PROFILE_EXPORT ...
Exporting sequence of schema PROFILE_EXPORT ...
Exporting profile of schema PROFILE_EXPORT ...
Exporting type of schema PROFILE_EXPORT ...
Exporting tables of schema PROFILE_EXPORT ...
Reading table objects of PROFILE_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of PROFILE_EXPORT
Exporting procedures/functions/triggers of schema PROFILE_EXPORT ...
Exporting views of schema PROFILE_EXPORT ...
Exporting synonyms of schema PROFILE_EXPORT ...
Exporting package of schema PROFILE_EXPORT ...
End of export schema PROFILE_EXPORT ...

Logical export succeeded.

SQL> imp users=profile_export file="./data/profile_export_txt.dmp" filetype = txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = PROFILE_EXPORT
-- DUMP FILE = ./data/profile_export_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

CT-00818, Profile has been assigned to user, can not been dropped without cascade option
Warning: profile can not been dropped or created
data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> DROP PROFILE test_profile CASCADE;

Succeed.

SQL> DROP PROFILE test_profile2 CASCADE;

Succeed.

SQL> DROP PROFILE test_profile3 CASCADE;

Succeed.

SQL> imp users=profile_export file="./data/profile_export_txt.dmp" filetype = txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = PROFILE_EXPORT
-- DUMP FILE = ./data/profile_export_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> exp users=profile_export file="./data/profile_export_bin.dmp" filetype = bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = PROFILE_EXPORT
-- FILE TYPE = BIN
-- DUMP FILE = ./data/profile_export_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema PROFILE_EXPORT ...
Exporting sequence of schema PROFILE_EXPORT ...
Exporting profile of schema PROFILE_EXPORT ...
Exporting type of schema PROFILE_EXPORT ...
Exporting tables of schema PROFILE_EXPORT ...
Reading table objects of PROFILE_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of PROFILE_EXPORT
Exporting procedures/functions/triggers of schema PROFILE_EXPORT ...
Exporting views of schema PROFILE_EXPORT ...
Exporting synonyms of schema PROFILE_EXPORT ...
Exporting package of schema PROFILE_EXPORT ...
End of export schema PROFILE_EXPORT ...

Logical export succeeded.

SQL> imp users=profile_export file="./data/profile_export_bin.dmp" filetype = bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = PROFILE_EXPORT
-- DUMP FILE = ./data/profile_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema PROFILE_EXPORT ... 
  Importing sequence of schema PROFILE_EXPORT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema PROFILE_EXPORT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema PROFILE_EXPORT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema PROFILE_EXPORT ,total number : 0 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema PROFILE_EXPORT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema PROFILE_EXPORT ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema PROFILE_EXPORT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema PROFILE_EXPORT ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema PROFILE_EXPORT ...
    Package importing success, 0 rows are loaded.

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user profile_export cascade;

Succeed.

SQL> DROP PROFILE test_profile CASCADE;

Succeed.

SQL> 
SQL> --- test self_object export ---
SQL> drop user if exists self_export cascade;

Succeed.

SQL> create user self_export identified by Changeme_123;

Succeed.

SQL> grant dba to self_export;

Succeed.

SQL> conn self_export/Changeme_123@127.0.0.1:1611

connected.

SQL> 
SQL> ---synonym---
SQL> DROP TABLE IF EXISTS test_synonym;

Succeed.

SQL> create table test_synonym (f1 int);

Succeed.

SQL> insert into test_synonym values (1);

1 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> DROP SYNONYM IF EXISTS synonym1;

Succeed.

SQL> CREATE OR REPLACE SYNONYM synonym1 for test_synonym
  2 /

Succeed.

SQL> 
SQL> DROP TYPE if exists my_type_3;

Succeed.

SQL> DROP TYPE if exists my_type_2;

Succeed.

SQL> DROP TYPE if exists my_type_1;

Succeed.

SQL> DROP TYPE if exists my_type_4;

Succeed.

SQL> ---type---
SQL> create or replace type my_type_1 is object (id number, name varchar2(64));
  2 /

Succeed.

SQL> create or replace type my_type_2 is table of my_type_1;
  2 /

Succeed.

SQL> create or replace type my_type_3 is table of my_type_2;
  2 /

Succeed.

SQL> create or replace type my_type_4 is object (id number, name varchar2(64));
  2 /

Succeed.

SQL> 
SQL> DROP TABLE IF EXISTS test_package;

Succeed.

SQL> create table test_package (f1 int);

Succeed.

SQL> insert into test_package values (1);

1 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> create or replace procedure test_alck(name varchar)
  2 is
  3 v1 int;
  4 begin 
  5 select get_lock(name) into v1 from test_package;
  6 sleep(10);
  7 select release_lock(name) into v1 from test_package;
  8 -- a :=1;
  9 end;
 10 /

Succeed.

SQL> 
SQL> DROP PACKAGE IF EXISTS DD;

Succeed.

SQL> CREATE OR REPLACE PACKAGE DD
  2 IS
  3 FUNCTION MYF(v1 int ,v2 int) RETURN INT; 
  4 PROCEDURE MYP;
  5 END;
  6 /

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE BODY DD
  2 IS
  3 FUNCTION MYF(v1 int,v2 int) RETURN INT
  4 is
  5 a int :=10;
  6 begin
  7 return v1+v2;
  8 end;
  9 end;
 10 /

Succeed.
Warning:
PL/SQL(SELF_EXPORT.DD) terminated with compiling errors
PLC-00966 Subprogram or variant 'MYP' has declared in package, but not defined in package body


SQL> 
SQL> DROP PACKAGE IF EXISTS PAK1;

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE PAK1
  2 IS
  3 FUNCTION MYF1 RETURN INT;
  4 PROCEDURE MYP1;
  5 END;
  6 /

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE BODY PAK1
  2 IS
  3 FUNCTION MYF1 RETURN INT
  4 IS
  5 V1 INT := 10;
  6 BEGIN
  7 NULL;
  8 RETURN V1;
  9 END;
 10 PROCEDURE MYP1 IS
 11 V1 INT;
 12 BEGIN
 13 SELECT MYF1 INTO V1 FROM test_package;
 14 DBE_OUTPUT.PRINT_LINE(V1);
 15 END;
 16 END;
 17 /

Succeed.

SQL> 
SQL> DROP PACKAGE IF EXISTS PAK2;

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE PAK2
  2 IS
  3 FUNCTION MYF2 RETURN INT;
  4 PROCEDURE MYP2;
  5 END;
  6 /

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE BODY PAK2
  2 IS
  3 FUNCTION MYF2 RETURN INT
  4 IS
  5 V1 INT := 20;
  6 BEGIN
  7 NULL;
  8 RETURN V1;
  9 END;
 10 PROCEDURE MYP2 IS
 11 V1 INT;
 12 BEGIN
 13 SELECT PAK1.MYF1 INTO V1 FROM test_package;
 14 DBE_OUTPUT.PRINT_LINE(V1);
 15 END;
 16 END;
 17 /

Succeed.

SQL> 
SQL> DROP PACKAGE IF EXISTS PAK3;

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE PAK3
  2 IS
  3 FUNCTION MYF3 RETURN INT;
  4 PROCEDURE MYP3;
  5 END;
  6 /

Succeed.

SQL> 
SQL> CREATE OR REPLACE PACKAGE BODY PAK3
  2 IS
  3 FUNCTION MYF3 RETURN INT
  4 IS
  5 V1 INT := 20;
  6 BEGIN
  7 NULL;
  8 RETURN V1;
  9 END;
 10 PROCEDURE MYP3 IS
 11 V1 INT;
 12 BEGIN
 13 SELECT PAK2.MYF2 INTO V1 FROM test_package;
 14 DBE_OUTPUT.PRINT_LINE(V1);
 15 END;
 16 END;
 17 /

Succeed.

SQL> 
SQL> 
SQL> CREATE OR REPLACE PROCEDURE "TEST_ALCK"
  2 (name varchar)
  3 is
  4 v1 int;
  5 begin 
  6 select get_lock(name) into v1 from test_package;
  7 sleep(10);
  8 select release_lock(name) into v1 from test_package;
  9 -- a :=1;
 10 end;
 11 /

Succeed.

SQL> 
SQL> exp users=self_export file="./data/self_export_txt.dmp" filetype = txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = SELF_EXPORT
-- FILE TYPE = TXT
-- DUMP FILE = ./data/self_export_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema SELF_EXPORT ...
Exporting sequence of schema SELF_EXPORT ...
Exporting profile of schema SELF_EXPORT ...
Exporting type of schema SELF_EXPORT ...
Exporting tables of schema SELF_EXPORT ...
Reading table objects of SELF_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TEST_SYNONYM                                                     1         
TEST_PACKAGE                                                     2         

Exporting tables (scripts or data) of SELF_EXPORT
exporting table SELF_EXPORT.TEST_SYNONYM ...
  exporting DDL of SELF_EXPORT.TEST_SYNONYM ...
  exporting data of SELF_EXPORT.TEST_SYNONYM ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_SYNONYM ...
  exporting constraints on SELF_EXPORT.TEST_SYNONYM ...

exporting table SELF_EXPORT.TEST_PACKAGE ...
  exporting DDL of SELF_EXPORT.TEST_PACKAGE ...
  exporting data of SELF_EXPORT.TEST_PACKAGE ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_PACKAGE ...
  exporting constraints on SELF_EXPORT.TEST_PACKAGE ...

Exporting procedures/functions/triggers of schema SELF_EXPORT ...
  exporting PROCEDURE SELF_EXPORT.TEST_ALCK
Exporting views of schema SELF_EXPORT ...
Exporting synonyms of schema SELF_EXPORT ...
Exporting package of schema SELF_EXPORT ...
End of export schema SELF_EXPORT ...

Logical export succeeded.

SQL> imp users=self_export file="./data/self_export_txt.dmp" filetype = txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = SELF_EXPORT
-- DUMP FILE = ./data/self_export_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> 
SQL> exp users=self_export file="./data/self_export_bin.dmp" filetype = bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = SELF_EXPORT
-- FILE TYPE = BIN
-- DUMP FILE = ./data/self_export_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema SELF_EXPORT ...
Exporting sequence of schema SELF_EXPORT ...
Exporting profile of schema SELF_EXPORT ...
Exporting type of schema SELF_EXPORT ...
Exporting tables of schema SELF_EXPORT ...
Reading table objects of SELF_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TEST_SYNONYM                                                     1         
TEST_PACKAGE                                                     2         

Exporting tables (scripts or data) of SELF_EXPORT
exporting table SELF_EXPORT.TEST_SYNONYM ...
  exporting DDL of SELF_EXPORT.TEST_SYNONYM ...
  exporting data of SELF_EXPORT.TEST_SYNONYM ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_SYNONYM ...
  exporting constraints on SELF_EXPORT.TEST_SYNONYM ...

exporting table SELF_EXPORT.TEST_PACKAGE ...
  exporting DDL of SELF_EXPORT.TEST_PACKAGE ...
  exporting data of SELF_EXPORT.TEST_PACKAGE ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_PACKAGE ...
  exporting constraints on SELF_EXPORT.TEST_PACKAGE ...

Exporting procedures/functions/triggers of schema SELF_EXPORT ...
  exporting PROCEDURE SELF_EXPORT.TEST_ALCK
Exporting views of schema SELF_EXPORT ...
Exporting synonyms of schema SELF_EXPORT ...
Exporting package of schema SELF_EXPORT ...
End of export schema SELF_EXPORT ...

Logical export succeeded.

SQL> imp users=self_export file="./data/self_export_bin.dmp" filetype = bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = SELF_EXPORT
-- DUMP FILE = ./data/self_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema SELF_EXPORT ... 
  Importing sequence of schema SELF_EXPORT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema SELF_EXPORT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema SELF_EXPORT ...
    Type importing success, 4 rows are loaded.

  Importing tables of schema SELF_EXPORT ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TEST_SYNONYM                                                     1                   
    TEST_PACKAGE                                                     1                   

  Importing foreign key of schema SELF_EXPORT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema SELF_EXPORT ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema SELF_EXPORT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema SELF_EXPORT ...
    Synonym importing success, 1 rows are loaded.

  Importing package of schema SELF_EXPORT ...
    Package importing success, 8 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> 
SQL> DROP TYPE if exists table_test;

Succeed.

SQL> CREATE OR REPLACE TYPE table_test IS TABLE OF VARCHAR(10);
  2 /

Succeed.

SQL> 
SQL> DECLARE
  2         v1 table_test;
  3 BEGIN
  4         v1 := table_test('ABC', 'def');
  5         DBE_OUTPUT.PRINT_LINE(v1(1));
  6         DBE_OUTPUT.PRINT_LINE(v1(2));
  7 END;
  8 /

PL/SQL procedure successfully completed.

SQL> 
SQL> exp users=self_export filetype=bin file='./data/type_export_bin.dmp';
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = SELF_EXPORT
-- FILE TYPE = BIN
-- DUMP FILE = ./data/type_export_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema SELF_EXPORT ...
Exporting sequence of schema SELF_EXPORT ...
Exporting profile of schema SELF_EXPORT ...
Exporting type of schema SELF_EXPORT ...
Exporting tables of schema SELF_EXPORT ...
Reading table objects of SELF_EXPORT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TEST_SYNONYM                                                     1         
TEST_PACKAGE                                                     2         

Exporting tables (scripts or data) of SELF_EXPORT
exporting table SELF_EXPORT.TEST_SYNONYM ...
  exporting DDL of SELF_EXPORT.TEST_SYNONYM ...
  exporting data of SELF_EXPORT.TEST_SYNONYM ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_SYNONYM ...
  exporting constraints on SELF_EXPORT.TEST_SYNONYM ...

exporting table SELF_EXPORT.TEST_PACKAGE ...
  exporting DDL of SELF_EXPORT.TEST_PACKAGE ...
  exporting data of SELF_EXPORT.TEST_PACKAGE ...
    data exporting success, 1 rows are dumped.

  exporting indexes on SELF_EXPORT.TEST_PACKAGE ...
  exporting constraints on SELF_EXPORT.TEST_PACKAGE ...

Exporting procedures/functions/triggers of schema SELF_EXPORT ...
  exporting PROCEDURE SELF_EXPORT.TEST_ALCK
Exporting views of schema SELF_EXPORT ...
Exporting synonyms of schema SELF_EXPORT ...
Exporting package of schema SELF_EXPORT ...
End of export schema SELF_EXPORT ...

Logical export succeeded.

SQL> drop type table_test;

Succeed.

SQL> imp users=self_export filetype=bin file='./data/type_export_bin.dmp';
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = SELF_EXPORT
-- DUMP FILE = ./data/type_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema SELF_EXPORT ... 
  Importing sequence of schema SELF_EXPORT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema SELF_EXPORT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema SELF_EXPORT ...
    Type importing success, 5 rows are loaded.

  Importing tables of schema SELF_EXPORT ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TEST_SYNONYM                                                     1                   
    TEST_PACKAGE                                                     1                   

  Importing foreign key of schema SELF_EXPORT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema SELF_EXPORT ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema SELF_EXPORT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema SELF_EXPORT ...
    Synonym importing success, 1 rows are loaded.

  Importing package of schema SELF_EXPORT ...
    Package importing success, 8 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user self_export cascade;

Succeed.

SQL> 
SQL> drop user if exists compatible_export1 cascade;

Succeed.

SQL> create user compatible_export1 identified by Test_123456;

Succeed.

SQL> grant dba to compatible_export1;

Succeed.

SQL> 
SQL> drop user if exists compatible_export2 cascade;

Succeed.

SQL> create user compatible_export2 identified by Test_123456;

Succeed.

SQL> grant dba to compatible_export2;

Succeed.

SQL> 
SQL> conn compatible_export1/Test_123456@127.0.0.1:1611

connected.

SQL> imp users=compatible_export1 file="./data/compatible_data/master_1.0.5/compatible_export_bin.dmp" filetype=bin parallel = 4;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = COMPATIBLE_EXPORT1
-- DUMP FILE = ./data/compatible_data/master_1.0.5/compatible_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema COMPATIBLE_EXPORT1 ... 
  Importing sequence of schema COMPATIBLE_EXPORT1 ...
    Sequence importing success, 0 rows are loaded.

  Importing tables of schema COMPATIBLE_EXPORT1 ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    COMPATIBLE_SYNONYM1                                              10000               
    COMPATIBLE_TABLE1                                                2                   

  Importing foreign key of schema COMPATIBLE_EXPORT1 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema COMPATIBLE_EXPORT1 ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema COMPATIBLE_EXPORT1 ...
    View importing success, 0 rows are loaded.


Importing schema COMPATIBLE_EXPORT2 ... 
  Importing sequence of schema COMPATIBLE_EXPORT2 ...
    Sequence importing success, 0 rows are loaded.

  Importing tables of schema COMPATIBLE_EXPORT2 ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema COMPATIBLE_EXPORT2 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema COMPATIBLE_EXPORT2 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema COMPATIBLE_EXPORT2 ...
    View importing success, 0 rows are loaded.

data importing success, 10002 rows are loaded.
Logical import succeeded.

SQL> select count(*) from compatible_export1.compatible_synonym1;

COUNT(*)            
--------------------
10000               

1 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> imp users=% file="./data/compatible_data/master_1.0.5/compatible_export_bin.dmp" filetype=bin parallel = 4;
Parsing import options ... 
Verify options ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_SCHEMAS
-- IMPORT OBJECTS = 
-- DUMP FILE = ./data/compatible_data/master_1.0.5/compatible_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema COMPATIBLE_EXPORT1 ... 
  Importing sequence of schema COMPATIBLE_EXPORT1 ...
    Sequence importing success, 0 rows are loaded.

  Importing tables of schema COMPATIBLE_EXPORT1 ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    COMPATIBLE_SYNONYM1                                              10000               
    COMPATIBLE_TABLE1                                                2                   

  Importing foreign key of schema COMPATIBLE_EXPORT1 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema COMPATIBLE_EXPORT1 ...
    Fuction/procedure/trigger importing success, 1 rows are loaded.

  Importing view of schema COMPATIBLE_EXPORT1 ...
    View importing success, 0 rows are loaded.


Importing schema COMPATIBLE_EXPORT2 ... 
  Importing sequence of schema COMPATIBLE_EXPORT2 ...
    Sequence importing success, 0 rows are loaded.

  Importing tables of schema COMPATIBLE_EXPORT2 ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    COMPATIBLE_SYNONYM2                                              9999                
    COMPATIBLE_TABLE2                                                2                   

  Importing foreign key of schema COMPATIBLE_EXPORT2 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema COMPATIBLE_EXPORT2 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema COMPATIBLE_EXPORT2 ...
    View importing success, 0 rows are loaded.

data importing success, 20003 rows are loaded.
Logical import succeeded.

SQL> select count(*) from compatible_export1.compatible_synonym1;

COUNT(*)            
--------------------
10000               

1 rows fetched.

SQL> select count(*) from compatible_export2.compatible_synonym2;

COUNT(*)            
--------------------
9999                

1 rows fetched.

SQL> 
SQL> drop user compatible_export1 cascade;

Succeed.

SQL> drop user compatible_export2 cascade;

Succeed.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> create tablespace ts_for_exp DATAFILE 'ts_for_exp.dbf' size 32M;

Succeed.

SQL> drop user if exists root_user cascade;

Succeed.

SQL> create user root_user identified by Test_123456;

Succeed.

SQL> grant dba to root_user;

Succeed.

SQL> drop tenant if exists tnt1 cascade;

Succeed.

SQL> create tenant tnt1 tablespaces(users, ts_for_exp);

Succeed.

SQL> alter session set tenant=tnt1;

Succeed.

SQL> create user tnt1_user1 identified by Test_123456;

Succeed.

SQL> grant dba to tnt1_user1;

Succeed.

SQL> conn tnt1_user1/Test_123456@127.0.0.1:1611/tnt1

connected.

SQL> exp users=tnt1$tnt1_user1 filetype=txt file='./data/user_in_tenant_export_bin.dmp' create_user=y grant=y;
Parsing export options ... 

CT-00130, Operation export/import is not supported on non-root tenant
Logical export failed.

SQL> imp filetype=txt file='./data/user_in_tenant_export_bin.dmp' create_user=y;
CT-00130, Operation export/import is not supported on non-root tenant
SQL> conn root_user/Test_123456@127.0.0.1:1611

connected.

SQL> exp users=tnt1$tnt1_user1 filetype=txt file='./data/user_in_tenant_export_bin.dmp' create_user=y grant=y;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TNT1$TNT1_USER1
-- FILE TYPE = TXT
-- DUMP FILE = ./data/user_in_tenant_export_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = Y
-- ROLE = N
-- GRANT = Y
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TNT1$TNT1_USER1 ...
Exporting user definition of schema TNT1$TNT1_USER1 ...
Exporting grant role and privilege of schema TNT1$TNT1_USER1 ...
Grant privilege to schema TNT1$TNT1_USER1 ...
Grant role to schema TNT1$TNT1_USER1 ...
Exporting sequence of schema TNT1$TNT1_USER1 ...
Exporting profile of schema TNT1$TNT1_USER1 ...
Exporting type of schema TNT1$TNT1_USER1 ...
Exporting tables of schema TNT1$TNT1_USER1 ...
Reading table objects of TNT1$TNT1_USER1

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of TNT1$TNT1_USER1
Exporting procedures/functions/triggers of schema TNT1$TNT1_USER1 ...
Exporting views of schema TNT1$TNT1_USER1 ...
Exporting synonyms of schema TNT1$TNT1_USER1 ...
Exporting package of schema TNT1$TNT1_USER1 ...
End of export schema TNT1$TNT1_USER1 ...

Logical export succeeded.

SQL> exp users=tnt1$tnt1_user1 filetype=txt file='./data/user_in_tenant_export_bin1.dmp' create_user=y grant=y tenant=y;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TNT1$TNT1_USER1
-- FILE TYPE = TXT
-- DUMP FILE = ./data/user_in_tenant_export_bin1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = Y
-- CREATE_USER = Y
-- ROLE = N
-- GRANT = Y
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TNT1$TNT1_USER1 ...
Exporting user definition of schema TNT1$TNT1_USER1 ...
Exporting grant role and privilege of schema TNT1$TNT1_USER1 ...
Grant privilege to schema TNT1$TNT1_USER1 ...
Grant role to schema TNT1$TNT1_USER1 ...
Exporting sequence of schema TNT1$TNT1_USER1 ...
Exporting profile of schema TNT1$TNT1_USER1 ...
Exporting type of schema TNT1$TNT1_USER1 ...
Exporting tables of schema TNT1$TNT1_USER1 ...
Reading table objects of TNT1$TNT1_USER1

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of TNT1$TNT1_USER1
Exporting procedures/functions/triggers of schema TNT1$TNT1_USER1 ...
Exporting views of schema TNT1$TNT1_USER1 ...
Exporting synonyms of schema TNT1$TNT1_USER1 ...
Exporting package of schema TNT1$TNT1_USER1 ...
End of export schema TNT1$TNT1_USER1 ...

Logical export succeeded.

SQL> drop tenant if exists tnt1 cascade;

Succeed.

SQL> imp filetype=txt file='./data/user_in_tenant_export_bin.dmp' create_user=y;
Parsing import options ... 
Verify options ...
  default to import current schema: ROOT_USER
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = ROOT_USER
-- DUMP FILE = ./data/user_in_tenant_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

CT-01394, The tenant TNT1 does not exist.
Incorrect sql during execution :
ALTER SESSION SET TENANT = TNT1

CT-01394, The tenant TNT1 does not exist.
Logical import failed.

SQL> SHOW TENANT_ID

TENANT_ID                                                       
----------------------------------------------------------------
0                                                               


SQL> SHOW TENANT_NAME

TENANT_NAME                                                     
----------------------------------------------------------------
TENANT$ROOT                                                     


SQL> create tenant tnt1 tablespaces(users);

Succeed.

SQL> imp filetype=txt file='./data/user_in_tenant_export_bin.dmp' create_user=y;
Parsing import options ... 
Verify options ...
  default to import current schema: ROOT_USER
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = ROOT_USER
-- DUMP FILE = ./data/user_in_tenant_export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> conn tnt1_user1/Test_123456@127.0.0.1:1611/tnt1

connected.

SQL> conn root_user/Test_123456@127.0.0.1:1611

connected.

SQL> drop tenant if exists tnt1 cascade;

Succeed.

SQL> imp filetype=txt file='./data/user_in_tenant_export_bin1.dmp' create_user=y;
Parsing import options ... 
Verify options ...
  default to import current schema: ROOT_USER
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = ROOT_USER
-- DUMP FILE = ./data/user_in_tenant_export_bin1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> SHOW TENANT_ID

TENANT_ID                                                       
----------------------------------------------------------------
0                                                               


SQL> SHOW TENANT_NAME

TENANT_NAME                                                     
----------------------------------------------------------------
TENANT$ROOT                                                     


SQL> conn tnt1_user1/Test_123456@127.0.0.1:1611/tnt1

connected.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists root_user cascade;

Succeed.

SQL> drop tenant if exists tnt1 cascade;

Succeed.

SQL> drop tablespace ts_for_exp;

Succeed.

SQL> 
SQL> CREATE or replace PROFILE test_profile_exp LIMIT PASSWORD_GRACE_TIME 10 PASSWORD_LOCK_TIME DEFAULT PASSWORD_LIFE_TIME UNLIMITED;

Succeed.

SQL> drop user if exists profile_exp_per CASCADE;

Succeed.

SQL> create user profile_exp_per identified by Changeme_123 PROFILE test_profile_exp;

Succeed.

SQL> grant create session to profile_exp_per;

Succeed.

SQL> exp users=profile_exp_per file="test_privileage.dmp";
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = PROFILE_EXP_PER
-- FILE TYPE = TXT
-- DUMP FILE = test_privileage.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema PROFILE_EXP_PER ...
Exporting sequence of schema PROFILE_EXP_PER ...
Exporting profile of schema PROFILE_EXP_PER ...
Exporting type of schema PROFILE_EXP_PER ...
Exporting tables of schema PROFILE_EXP_PER ...
Reading table objects of PROFILE_EXP_PER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of PROFILE_EXP_PER
Exporting procedures/functions/triggers of schema PROFILE_EXP_PER ...
Exporting views of schema PROFILE_EXP_PER ...
Exporting synonyms of schema PROFILE_EXP_PER ...
Exporting package of schema PROFILE_EXP_PER ...
End of export schema PROFILE_EXP_PER ...

Logical export succeeded.

SQL> DROP PROFILE test_profile_exp CASCADE;

Succeed.

SQL> conn profile_exp_per/Changeme_123@127.0.0.1:1611

connected.

SQL> imp users=profile_exp_per file="test_privileage.dmp";
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = PROFILE_EXP_PER
-- DUMP FILE = test_privileage.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

CT-01001, Permissions were insufficient
Warning: profile can not been dropped or created
data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user profile_exp_per cascade;

Succeed.

SQL> DROP PROFILE test_profile_exp CASCADE;

CT-00785, Profile TEST_PROFILE_EXP does not exist
SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists usdpdbc01 cascade;

Succeed.

SQL> drop user if exists usdpdb cascade;

Succeed.

SQL> create user usdpdbc01 identified by Changeme_123;

Succeed.

SQL> GRANT CREATE VIEW TO usdpdbc01;

Succeed.

SQL> GRANT SELECT ANY TABLE TO usdpdbc01;

Succeed.

SQL> GRANT UNLIMITED TABLESPACE TO usdpdbc01;

Succeed.

SQL> GRANT CONNECT TO usdpdbc01;

Succeed.

SQL> GRANT RESOURCE TO usdpdbc01;

Succeed.

SQL> exp users=usdpdbc01 file="wyj.txt" filetype=bin create_user=y grant=y;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = USDPDBC01
-- FILE TYPE = BIN
-- DUMP FILE = wyj.txt
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = Y
-- ROLE = N
-- GRANT = Y
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema USDPDBC01 ...
Exporting user definition of schema USDPDBC01 ...
Exporting grant role and privilege of schema USDPDBC01 ...
Grant privilege to schema USDPDBC01 ...
Grant role to schema USDPDBC01 ...
Exporting sequence of schema USDPDBC01 ...
Exporting profile of schema USDPDBC01 ...
Exporting type of schema USDPDBC01 ...
Exporting tables of schema USDPDBC01 ...
Reading table objects of USDPDBC01

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------

Exporting tables (scripts or data) of USDPDBC01
Exporting procedures/functions/triggers of schema USDPDBC01 ...
Exporting views of schema USDPDBC01 ...
Exporting synonyms of schema USDPDBC01 ...
Exporting package of schema USDPDBC01 ...
End of export schema USDPDBC01 ...

Logical export succeeded.

SQL> drop user if exists usdpdbc01 cascade;

Succeed.

SQL> create user usdpdb identified by Changeme_123;

Succeed.

SQL> grant dba to usdpdb;

Succeed.

SQL> conn usdpdb/Changeme_123@127.0.0.1:1611

connected.

SQL> imp remap_schema=usdpdbc01:usdpdb log="daochulog.txt" create_user = y filetype=bin file="wyj.txt";
Parsing import options ... 
Verify options ...
  verify remap schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = REMAP_SCHEMA
-- REMAP SCHEMA = USDPDBC01:usdpdb
-- DUMP FILE = wyj.txt
-- LOG FILE = daochulog.txt
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = Y
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema USDPDBC01 ... 
  Importing sequence of schema USDPDBC01 ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema USDPDBC01 ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema USDPDBC01 ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema USDPDBC01 ,total number : 0 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema USDPDBC01 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema USDPDBC01 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema USDPDBC01 ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema USDPDBC01 ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema USDPDBC01 ...
    Package importing success, 0 rows are loaded.

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT cascade;

Succeed.

SQL> create user MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT identified by Changeme_123;

Succeed.

SQL> grant dba to MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

Succeed.

SQL> conn MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT/Changeme_123@127.0.0.1:1611

connected.

SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

Succeed.

SQL> create table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT(f1 int, f2 varchar(100));

Succeed.

SQL> insert into MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT values(1,'test');

1 rows affected.

SQL> insert into MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT values(2,'test');

1 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> exp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_64_txt.sql" parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- FILE TYPE = TXT
-- DUMP FILE = tablename_64_txt.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

Logical export succeeded.

SQL> exp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=bin file = "tablename_64_bin.sql" parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- FILE TYPE = BIN
-- DUMP FILE = tablename_64_bin.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    data exporting success! 2 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

Logical export succeeded.

SQL> 
SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

Succeed.

SQL> imp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_64_txt.sql" parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- DUMP FILE = tablename_64_txt.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 3 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> 
SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

Succeed.

SQL> imp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=bin file = "tablename_64_bin.sql" parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- DUMP FILE = tablename_64_bin.sql
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT 2                   

  Importing foreign key of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Package importing success, 0 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> 
SQL> exp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000" parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- FILE TYPE = TXT
-- DUMP FILE = tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

Logical export succeeded.

SQL> exp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000.sql" parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- FILE TYPE = TXT
-- DUMP FILE = tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000.sql
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

Logical export succeeded.

SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

Succeed.

SQL> imp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000" parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- DUMP FILE = tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 3 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> imp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT filetype=txt file = "tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000.sql" parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- DUMP FILE = tablename_exceed64_00000_00000_00000_00000_00000_00000_00000_000.sql
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 3 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> 
SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1;

Succeed.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2;

Succeed.

SQL> create table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 (c int);

Succeed.

SQL> alter table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 add constraint t1_pkk primary key(c);

Succeed.

SQL> insert into MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 values(1),(2),(10);

3 rows affected.

SQL> commit;

Succeed.

SQL> exp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 remap_tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1:MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 filetype=bin file="exp_remap_tables.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1
-- FILE TYPE = BIN
-- DUMP FILE = exp_remap_tables.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 ...
  exporting data of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 ...
    data exporting success, 3 rows are dumped.

  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1 ...

Logical export succeeded.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1;

Succeed.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2;

Succeed.

SQL> imp tables=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 filetype=bin file="exp_remap_tables.dmp";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2
-- DUMP FILE = exp_remap_tables.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 3                   

  Importing foreign key of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Package importing success, 0 rows are loaded.

data importing success, 3 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2;

COUNT(*)            
--------------------
3                   

1 rows fetched.

SQL> 
SQL> DROP SYNONYM IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_synomy1;

Succeed.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3;

Succeed.

SQL> create table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 (c int);

Succeed.

SQL> insert into MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 values(1),(2),(10);

3 rows affected.

SQL> commit;

Succeed.

SQL> CREATE OR REPLACE SYNONYM MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_synomy1 for MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3
  2 /

Succeed.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_synomy1;

COUNT(*)            
--------------------
3                   

1 rows fetched.

SQL> 
SQL> CREATE OR REPLACE PROCEDURE MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_procedu(param1 out varchar2)
  2 IS
  3     tmp varchar2(20) :='12345678';
  4 begin
  5     dbe_output.print_line('OUT PUT RESULT:'||param1);
  6 end MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_procedu;
  7 /

Succeed.

SQL> 
SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger;

Succeed.

SQL> CREATE TABLE MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger (F_INT1 INT, F_INT2 INT, F_CHAR1 CHAR(16), F_DATE DATE);

Succeed.

SQL> INSERT INTO MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger VALUES(2,2,'A','2017-12-11 14:08:00');

1 rows affected.

SQL> commit;

Succeed.

SQL> CREATE OR REPLACE TRIGGER MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger BEFORE INSERT ON MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger
  2 FOR EACH ROW
  3 BEGIN
  4     UPDATE MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_trigger SET F_INT1 = 1;
  5 END;
  6 /

Succeed.

SQL> 
SQL> DROP TABLE IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobname;

Succeed.

SQL> CREATE TABLE MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobname (F_INT1 INT, MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobnam1 CLOB, MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobnam2 BLOB);

Succeed.

SQL> insert into MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobname values(1, 'sadfasfsadfsdfasfa', '1010010001001');

1 rows affected.

SQL> commit;

Succeed.

SQL> exp users=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT file="maxlen_user.dmp" filetype=bin parallel=4;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- FILE TYPE = BIN
-- DUMP FILE = maxlen_user.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting sequence of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting profile of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting type of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting tables of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Reading table objects of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT 1         
MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 2         
MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 3         
MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER 4         
MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME 5         

Exporting tables (scripts or data) of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    data exporting success! 2 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 ...
    data exporting success! 3 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 ...

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 ...
    data exporting success! 3 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 ...

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER ...
    data exporting success! 1 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER ...

exporting table MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME ...
  exporting DDL of MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME ...
    data exporting success! 1 rows are dumped.
  exporting indexes on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME ...
  exporting constraints on MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME ...

Exporting procedures/functions/triggers of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
  exporting PROCEDURE MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_PROCEDU
  exporting TRIGGER MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT.MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER
Exporting views of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting synonyms of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
Exporting package of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
End of export schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...

Logical export succeeded.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN1;

Succeed.

SQL> drop table if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2;

Succeed.

SQL> DROP SYNONYM IF EXISTS MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_synomy1;

Succeed.

SQL> imp users=MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT file="maxlen_user.dmp" filetype=bin parallel=4;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT
-- DUMP FILE = maxlen_user.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ... 
  Importing sequence of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ,total number : 5 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT 2                   
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2 3                   
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN3 3                   
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_TRIGGER 1                   
    MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_LOBNAME 1                   

  Importing foreign key of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Fuction/procedure/trigger importing success, 2 rows are loaded.

  Importing view of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Synonym importing success, 1 rows are loaded.

  Importing package of schema MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT ...
    Package importing success, 0 rows are loaded.

data importing success, 10 rows are loaded.
Logical import succeeded.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_lobname;

COUNT(*)            
--------------------
1                   

1 rows fetched.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_synomy1;

COUNT(*)            
--------------------
3                   

1 rows fetched.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTEN2;

COUNT(*)            
--------------------
3                   

1 rows fetched.

SQL> select count(*) from MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists MO_NE_471_STATUSABTEST_STATRESULT_SGSVLRLNK_C426B29786F9_CONTENT cascade;

Succeed.

SQL> 
SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001 cascade;

Succeed.

SQL> create user test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001 identified by Test_123456;

Succeed.

SQL> grant dba to test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001;

Succeed.

SQL> conn test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001/Test_123456@127.0.0.1:1611

connected.

SQL> create table ts1 (c int);

Succeed.

SQL> insert into ts1 values(1),(2);

2 rows affected.

SQL> commit;

Succeed.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002 cascade;

Succeed.

SQL> create user test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002 identified by Test_123456;

Succeed.

SQL> grant dba to test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002;

Succeed.

SQL> conn test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002/Test_123456@127.0.0.1:1611

connected.

SQL> create table ts2 (c int);

Succeed.

SQL> insert into ts2 values(3),(4);

2 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> exp users=test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001,test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002 file="test_schema_remap64.dmp" filetype=bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001, TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002
-- FILE TYPE = BIN
-- DUMP FILE = test_schema_remap64.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting sequence of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting profile of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting type of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting tables of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Reading table objects of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TS1                                                              1         

Exporting tables (scripts or data) of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001
exporting table TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001.TS1 ...
  exporting DDL of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001.TS1 ...
  exporting data of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001.TS1 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001.TS1 ...
  exporting constraints on TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001.TS1 ...

Exporting procedures/functions/triggers of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting views of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting synonyms of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
Exporting package of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
End of export schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...

Exporting schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting sequence of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting profile of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting type of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting tables of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Reading table objects of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TS2                                                              1         

Exporting tables (scripts or data) of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002
exporting table TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002.TS2 ...
  exporting DDL of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002.TS2 ...
  exporting data of TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002.TS2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002.TS2 ...
  exporting constraints on TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002.TS2 ...

Exporting procedures/functions/triggers of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting views of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting synonyms of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
Exporting package of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
End of export schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...

Logical export succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003 cascade;

Succeed.

SQL> create user test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003 identified by Test_123456;

Succeed.

SQL> grant dba to test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003;

Succeed.

SQL> imp file="test_schema_remap64.dmp" filetype=bin remap_schema=test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001:test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003;
Parsing import options ... 
Verify options ...
  verify remap schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = REMAP_SCHEMA
-- REMAP SCHEMA = TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001:test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003
-- DUMP FILE = test_schema_remap64.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ... 
  Importing sequence of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TS1                                                              2                   

  Importing foreign key of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_001 ...
    Package importing success, 0 rows are loaded.


Importing schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ... 
  Importing sequence of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------

  Importing foreign key of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TEST_REMAP_USER_EXCEED64_00000_00000_00000_00000_00000_00000_002 ...
    Package importing success, 0 rows are loaded.

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> select count(*) from test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001.ts1;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> select count(*) from test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003.ts1;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> select count(*) from test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002.ts2;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_001 cascade;

Succeed.

SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_002 cascade;

Succeed.

SQL> drop user if exists test_remap_user_exceed64_00000_00000_00000_00000_00000_00000_003 cascade;

Succeed.

SQL> 
SQL> create tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01 datafile 'tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01' size 16m autoextend on next 16m;

Succeed.

SQL> create tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_02 datafile 'tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_02' size 16m autoextend on next 16m; 

Succeed.

SQL> drop user if exists test_remap cascade;

Succeed.

SQL> create user test_remap identified by Test_123456;

Succeed.

SQL> grant dba to test_remap;

Succeed.

SQL> conn test_remap/Test_123456@127.0.0.1:1611

connected.

SQL> create table ts1 (c int) tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01;

Succeed.

SQL> insert into ts1 values(1),(2);

2 rows affected.

SQL> commit;

Succeed.

SQL> create table ts2 (c int) tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01;

Succeed.

SQL> insert into ts2 values(3),(4);

2 rows affected.

SQL> commit;

Succeed.

SQL> create table ts3 (c int) tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01;

Succeed.

SQL> insert into ts3 values(5),(6);

2 rows affected.

SQL> commit;

Succeed.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> exp users=test_remap file="test_remap64_tablespace.dmp" filetype=bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = TEST_REMAP
-- FILE TYPE = BIN
-- DUMP FILE = test_remap64_tablespace.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema TEST_REMAP ...
Exporting sequence of schema TEST_REMAP ...
Exporting profile of schema TEST_REMAP ...
Exporting type of schema TEST_REMAP ...
Exporting tables of schema TEST_REMAP ...
Reading table objects of TEST_REMAP

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TS1                                                              1         
TS2                                                              2         
TS3                                                              3         

Exporting tables (scripts or data) of TEST_REMAP
exporting table TEST_REMAP.TS1 ...
  exporting DDL of TEST_REMAP.TS1 ...
  exporting data of TEST_REMAP.TS1 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TEST_REMAP.TS1 ...
  exporting constraints on TEST_REMAP.TS1 ...

exporting table TEST_REMAP.TS2 ...
  exporting DDL of TEST_REMAP.TS2 ...
  exporting data of TEST_REMAP.TS2 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TEST_REMAP.TS2 ...
  exporting constraints on TEST_REMAP.TS2 ...

exporting table TEST_REMAP.TS3 ...
  exporting DDL of TEST_REMAP.TS3 ...
  exporting data of TEST_REMAP.TS3 ...
    data exporting success, 2 rows are dumped.

  exporting indexes on TEST_REMAP.TS3 ...
  exporting constraints on TEST_REMAP.TS3 ...

Exporting procedures/functions/triggers of schema TEST_REMAP ...
Exporting views of schema TEST_REMAP ...
Exporting synonyms of schema TEST_REMAP ...
Exporting package of schema TEST_REMAP ...
End of export schema TEST_REMAP ...

Logical export succeeded.

SQL> conn test_remap/Test_123456@127.0.0.1:1611

connected.

SQL> drop table ts1;

Succeed.

SQL> drop table ts2;

Succeed.

SQL> drop table ts3;

Succeed.

SQL> drop tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_01 including contents and datafiles;

Succeed.

SQL> 
SQL> conn test_remap/Test_123456@127.0.0.1:1611

connected.

SQL> imp tables=ts1,ts3 file="test_remap64_tablespace.dmp" filetype=bin REMAP_TABLESPACE=TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_01:TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_02;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TS1, TS3
-- DUMP FILE = test_remap64_tablespace.dmp
-- LOG FILE = 
-- REMAP TABLESPACE = TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_01:TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_02
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema TEST_REMAP ... 
  Importing sequence of schema TEST_REMAP ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TEST_REMAP ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TEST_REMAP ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TEST_REMAP ,total number : 3 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TS1                                                              2                   
    TS3                                                              2                   

  Importing foreign key of schema TEST_REMAP ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TEST_REMAP ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema TEST_REMAP ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TEST_REMAP ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TEST_REMAP ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> select count(*) from ts1;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> select count(*) from ts3;

COUNT(*)            
--------------------
2                   

1 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> select TABLE_NAME,TABLESPACE_NAME from db_tables where OWNER = UPPER('test_remap') order by TABLE_NAME;

TABLE_NAME                                                       TABLESPACE_NAME                                                 
---------------------------------------------------------------- ----------------------------------------------------------------
TS1                                                              TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_02
TS3                                                              TABLESPACE_EXCEED64_00000_00000_00000_00000_00000_00000_00000_02

2 rows fetched.

SQL> drop user test_remap cascade;

Succeed.

SQL> drop tablespace tablespace_exceed64_00000_00000_00000_00000_00000_00000_00000_02 including contents and datafiles;

Succeed.

SQL> 
SQL> -- DTS202105120JB1F7P0G00
SQL> drop user if exists cmbtest cascade;

Succeed.

SQL> create user cmbtest identified by Changeme_123;

Succeed.

SQL> grant dba to cmbtest;

Succeed.

SQL> conn cmbtest/Changeme_123@127.0.0.1:1611

connected.

SQL> 
SQL> drop table if exists tbl_interval;

Succeed.

SQL> create table tbl_interval(
  2 col_int int AUTO_INCREMENT ,
  3 col_integer integer,
  4 col_BINARY_INTEGER BINARY_INTEGER,
  5 col_smallint smallint not null default '7',
  6 col_bigint bigint not null default '3',
  7 col_BINARY_BIGINT BINARY_BIGINT,
  8 col_real real,
  9 col_double double comment 'double',
 10 col_float float,
 11 col_BINARY_DOUBLE BINARY_DOUBLE,
 12 col_decimal decimal,
 13 col_number1 number,
 14 col_number2 number(38),
 15 col_number3 number(38,-84),
 16 col_number4 number(38,127),
 17 col_number5 number(38,7),
 18 col_numeric numeric,
 19 col_char1 char(1000),
 20 col_char2 char(8000),
 21 col_nchar1 nchar(3000),
 22 col_nchar2 nchar(8000),
 23 col_varchar_200 varchar(200),
 24 col_varchar_8000 varchar(8000) not null default 'abcd',
 25 col_varchar2_1000 varchar2(1000),
 26 col_varchar2_8000 varchar2(8000),
 27 col_nvarchar1 nvarchar(1000),
 28 col_nvarchar2 nvarchar(8000),
 29 col_nvarchar2_1000 nvarchar2(1000),
 30 col_nvarchar2_8000 nvarchar2(8000),
 31 col_clob clob,
 32 col_text text,
 33 col_longtext longtext not null,
 34 col_image image,
 35 col_binary1 binary(2000),
 36 col_binary2 binary(8000),
 37 col_varbinary1 varbinary(1000),
 38 col_varbinary2 varbinary(8000) not null,
 39 col_raw1 raw(1000),
 40 col_raw2 raw(8000),
 41 col_blob blob,
 42 col_date date not null default to_date('2018-06-01','yyyy-mm-dd'),
 43 col_datetime datetime default '2018-01-07 08:08:08',
 44 col_timestamp1 timestamp default to_timestamp('2018-01-07 08:08:08', 'YYYY-MM-DD HH24:MI:SS:FF'),
 45 col_timestamp2 timestamp(6),
 46 col_timestamp3 TIMESTAMP WITH TIME ZONE,
 47 col_timestamp4 TIMESTAMP WITH LOCAL TIME ZONE,
 48 col_bool bool,
 49 col_boolean boolean,
 50 col_interval1 INTERVAL YEAR TO MONTH,
 51 col_interval2 INTERVAL DAY TO SECOND,
 52 primary key(col_int,col_bigint)
 53 );

Succeed.

SQL> --增加唯一约束
SQL> alter table tbl_interval add constraint cos_interval_uk1 unique(col_nvarchar1,col_raw1);

Succeed.

SQL> --函数索引目前支持to_char、upper
SQL> create index idx_tbl_interval_fun_01 on tbl_interval(to_char(col_BINARY_BIGINT) asc,upper(col_int) desc);

Succeed.

SQL> create index idx_tbl_interval_fun_02 on tbl_interval(to_char(col_interval2) asc,upper(col_timestamp4) desc);

Succeed.

SQL> --动态扩展interval
SQL> drop table if exists T_TESTNODEB;

Succeed.

SQL> CREATE TABLE "T_TESTNODEB"
  2 (
  3 "PLANID" BINARY_INTEGER NOT NULL,
  4 "NODEBID" BINARY_INTEGER NOT NULL,
  5 PRIMARY KEY("PLANID", "NODEBID")
  6 );

Succeed.

SQL> INSERT INTO "T_TESTNODEB" ("PLANID","NODEBID") values
  2 (1,1);

1 rows affected.

SQL> INSERT INTO "T_TESTNODEB" ("PLANID","NODEBID") values
  2 (2,1);

1 rows affected.

SQL> INSERT INTO "T_TESTNODEB" ("PLANID","NODEBID") values
  2 (4,1);

1 rows affected.

SQL> INSERT INTO "T_TESTNODEB" ("PLANID","NODEBID") values
  2 (5,1);

1 rows affected.

SQL> COMMIT;

Succeed.

SQL> CREATE INDEX "IDX_T_TESTNODEB2" ON "T_TESTNODEB"("NODEBID")
  2 TABLESPACE "CMEDB"
  3 INITRANS 2
  4 PCTFREE 8;

CT-00780, The tablespace CMEDB does not exist.
SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> 
SQL> exp users=cmbtest file="exp_alter_bin.dmp" parallel=4 insert_batch=8 COMMIT_BATCH=1000 filetype=bin;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = CMBTEST
-- FILE TYPE = BIN
-- DUMP FILE = exp_alter_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 8
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema CMBTEST ...
Exporting sequence of schema CMBTEST ...
Exporting profile of schema CMBTEST ...
Exporting type of schema CMBTEST ...
Exporting tables of schema CMBTEST ...
Reading table objects of CMBTEST

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TBL_INTERVAL                                                     1         
T_TESTNODEB                                                      2         

Exporting tables (scripts or data) of CMBTEST
exporting table CMBTEST.TBL_INTERVAL ...
  exporting DDL of CMBTEST.TBL_INTERVAL ...
    data exporting success! 0 rows are dumped.
  exporting auto_increment attr on CMBTEST.TBL_INTERVAL ...
  exporting indexes on CMBTEST.TBL_INTERVAL ...
  exporting constraints on CMBTEST.TBL_INTERVAL ...

exporting table CMBTEST.T_TESTNODEB ...
  exporting DDL of CMBTEST.T_TESTNODEB ...
    data exporting success! 4 rows are dumped.
  exporting indexes on CMBTEST.T_TESTNODEB ...
  exporting constraints on CMBTEST.T_TESTNODEB ...

Exporting procedures/functions/triggers of schema CMBTEST ...
Exporting views of schema CMBTEST ...
Exporting synonyms of schema CMBTEST ...
Exporting package of schema CMBTEST ...
End of export schema CMBTEST ...

Logical export succeeded.

SQL> imp users=cmbtest FILE="exp_alter_bin.dmp" log="exp_alter_bin.log" parallel=1 BATCH_COUNT=1 filetype=bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = CMBTEST
-- DUMP FILE = exp_alter_bin.dmp
-- LOG FILE = exp_alter_bin.log
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 1
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema CMBTEST ... 
  Importing sequence of schema CMBTEST ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema CMBTEST ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema CMBTEST ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema CMBTEST ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TESTNODEB                                                      4                   

  Importing foreign key of schema CMBTEST ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema CMBTEST ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema CMBTEST ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema CMBTEST ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema CMBTEST ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> imp users=cmbtest FILE="exp_alter_bin.dmp" log="exp_alter_bin.log" parallel=2 ddl_parallel=2 BATCH_COUNT=1 filetype=bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = CMBTEST
-- DUMP FILE = exp_alter_bin.dmp
-- LOG FILE = exp_alter_bin.log
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 2
-- DDL_PARALLEL = 2
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 1
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema CMBTEST ... 
  Importing sequence of schema CMBTEST ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema CMBTEST ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema CMBTEST ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema CMBTEST ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    T_TESTNODEB                                                      4                   

  Importing foreign key of schema CMBTEST ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema CMBTEST ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema CMBTEST ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema CMBTEST ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema CMBTEST ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> 
SQL> exp users=cmbtest file="exp_alter_txt.dmp" parallel=4 insert_batch=8 COMMIT_BATCH=1000 filetype=txt;
Parsing export options ... 
Verify options ...
  verify schema ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = SCHEMA
-- EXPORT OBJECTS = CMBTEST
-- FILE TYPE = TXT
-- DUMP FILE = exp_alter_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 8
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Exporting schema CMBTEST ...
Exporting sequence of schema CMBTEST ...
Exporting profile of schema CMBTEST ...
Exporting type of schema CMBTEST ...
Exporting tables of schema CMBTEST ...
Reading table objects of CMBTEST

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
TBL_INTERVAL                                                     1         
T_TESTNODEB                                                      2         

Exporting tables (scripts or data) of CMBTEST
exporting table CMBTEST.TBL_INTERVAL ...
  exporting DDL of CMBTEST.TBL_INTERVAL ...
  exporting auto_increment attr on CMBTEST.TBL_INTERVAL ...
  exporting indexes on CMBTEST.TBL_INTERVAL ...
  exporting constraints on CMBTEST.TBL_INTERVAL ...

exporting table CMBTEST.T_TESTNODEB ...
  exporting DDL of CMBTEST.T_TESTNODEB ...
  exporting indexes on CMBTEST.T_TESTNODEB ...
  exporting constraints on CMBTEST.T_TESTNODEB ...

Exporting procedures/functions/triggers of schema CMBTEST ...
Exporting views of schema CMBTEST ...
Exporting synonyms of schema CMBTEST ...
Exporting package of schema CMBTEST ...
End of export schema CMBTEST ...

Logical export succeeded.

SQL> imp users=cmbtest FILE="exp_alter_txt.dmp" log="aaaa.log" parallel=1 BATCH_COUNT=1 filetype=txt;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = CMBTEST
-- DUMP FILE = exp_alter_txt.dmp
-- LOG FILE = aaaa.log
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 1
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 2 rows are loaded.
Logical import succeeded.

SQL> drop user if exists cmbtest cascade;

Succeed.

SQL> 
SQL> -- DTS2021051306F8GHP1300
SQL> CREATE TABLESPACE NCISLOB datafile 'NCISLOB' size 4M autoextend on next 32M extent autoallocate;

Succeed.

SQL> CREATE TABLESPACE NCISBLOB datafile 'NCISBLOB' size 4M autoextend on next 32M extent autoallocate;

Succeed.

SQL> CREATE TABLESPACE NCISDAT datafile 'NCISDAT' size 4M autoextend on next 32M extent autoallocate;

Succeed.

SQL> drop user if exists ncisdbau cascade;

Succeed.

SQL> create user ncisdbau identified by Cantian_234;

Succeed.

SQL> alter user ncisdbau default tablespace NCISDAT;

Succeed.

SQL> grant dba to ncisdbau;

Succeed.

SQL> conn ncisdbau/Cantian_234@127.0.0.1:1611

connected.

SQL> drop table if exists S31T1_CRD_AHN_TXN_JRNL_000001;

Succeed.

SQL> CREATE TABLE S31T1_CRD_AHN_TXN_JRNL_000001
  2 (
  3 RSRV_FLD_DSC            CLOB,
  4 RSRV_FLD_DSC_B          BLOB,
  5 SYS_SND_SERIAL_NO       CHAR(10) ,
  6 SYS_TX_TYPE             CHAR(6) ,
  7 MULTI_TENANCY_ID        CHAR(6) ,
  8 TXN_DT                  CHAR(20) 
  9 )
 10 LOB(RSRV_FLD_DSC) STORE AS(
 11 	TABLESPACE NCISLOB
 12 )
 13 LOB(RSRV_FLD_DSC_B) STORE AS(
 14 	TABLESPACE NCISBLOB
 15 )
 16 PARTITION BY RANGE ("MULTI_TENANCY_ID","TXN_DT")
 17 (
 18         PARTITION PCN000_20180727 VALUES LESS THAN ('CN000','20180728') TABLESPACE "NCISDAT" INITRANS 2 PCTFREE 10
 19 )TABLESPACE "NCISDAT";

Succeed.

SQL> 
SQL> show create table S31T1_CRD_AHN_TXN_JRNL_000001;

CREATE TABLE "S31T1_CRD_AHN_TXN_JRNL_000001"
(
  "RSRV_FLD_DSC" CLOB,
  "RSRV_FLD_DSC_B" BLOB,
  "SYS_SND_SERIAL_NO" CHAR(10 BYTE),
  "SYS_TX_TYPE" CHAR(6 BYTE),
  "MULTI_TENANCY_ID" CHAR(6 BYTE),
  "TXN_DT" CHAR(20 BYTE)
)
LOB ("RSRV_FLD_DSC") STORE AS (
    TABLESPACE "NCISLOB"
)
LOB ("RSRV_FLD_DSC_B") STORE AS (
    TABLESPACE "NCISBLOB"
)
PARTITION BY RANGE ("MULTI_TENANCY_ID", "TXN_DT")
(
    PARTITION PCN000_20180727 VALUES LESS THAN ('CN000','20180728') TABLESPACE "NCISDAT" INITRANS 2 PCTFREE 10 FORMAT ASF
)
TABLESPACE "NCISDAT"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;



SQL> exp tables=S31T1_CRD_AHN_TXN_JRNL_000001 file='lob_storage.txt';
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = S31T1_CRD_AHN_TXN_JRNL_000001
-- FILE TYPE = TXT
-- DUMP FILE = lob_storage.txt
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting DDL of NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting data of NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting constraints on NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...

Logical export succeeded.

SQL> imp tables=S31T1_CRD_AHN_TXN_JRNL_000001 file='lob_storage.txt';
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = S31T1_CRD_AHN_TXN_JRNL_000001
-- DUMP FILE = lob_storage.txt
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> 
SQL> exp tables=S31T1_CRD_AHN_TXN_JRNL_000001 file='lob_storage.bin' consistent=y;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = S31T1_CRD_AHN_TXN_JRNL_000001
-- FILE TYPE = TXT
-- DUMP FILE = lob_storage.bin
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = Y
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting DDL of NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting data of NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...
  exporting constraints on NCISDBAU.S31T1_CRD_AHN_TXN_JRNL_000001 ...

Logical export succeeded.

SQL> imp tables=S31T1_CRD_AHN_TXN_JRNL_000001 file='lob_storage.bin';
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = S31T1_CRD_AHN_TXN_JRNL_000001
-- DUMP FILE = lob_storage.bin
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> 
SQL> drop table if exists S31T1_CRD_AHN_TXN_JRNL_000001;

Succeed.

SQL> drop user if exists ncisdbau cascade;

Succeed.

SQL> drop TABLESPACE NCISLOB INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> drop TABLESPACE NCISBLOB INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> drop TABLESPACE NCISDAT INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> 
SQL> -- 	DTS2021051703VS9FP1400
SQL> CREATE TABLESPACE TABLE_COMPRESS_TEST DATAFILE 'normal_object_compress_test' size 10M AUTOEXTEND on extent autoallocate;

Succeed.

SQL> CREATE TABLESPACE TABLE_COMPRESS_MAP DATAFILE 'normal_object_compress_map' size 10M compress AUTOEXTEND on extent autoallocate;

Succeed.

SQL> CREATE TABLESPACE TABLE_COMPRESS_THREE DATAFILE 'normal_object_compress_three' size 10M compress AUTOEXTEND on extent autoallocate;

Succeed.

SQL> drop user if exists cmbtest cascade;

Succeed.

SQL> create user cmbtest identified by Changeme_123;

Succeed.

SQL> grant dba to cmbtest;

Succeed.

SQL> conn CMBTEST/Changeme_123@127.0.0.1:1611

connected.

SQL> 
SQL> DROP TABLE IF EXISTS education;

Succeed.

SQL> CREATE TABLE education(staff_id INT NOT NULL, highest_degree CHAR(8), graduate_school VARCHAR(64), graduate_date DATETIME, education_note VARCHAR(70))
  2 PARTITION BY LIST(highest_degree)
  3 (
  4 PARTITION doctor VALUES ('博士'),
  5 PARTITION master VALUES ('硕士'),
  6 PARTITION undergraduate VALUES ('学士')
  7 );

Succeed.

SQL> --向表education中插入记录1。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(10,'博士','西安电子科技大学','2017-07-06 12:00:00','211');

1 rows affected.

SQL> --向表education中插入记录2。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(11,'博士','西北农林科技大学','2017-07-06 12:00:00','211和985');

1 rows affected.

SQL> --向表education中插入记录3。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(12,'硕士','西北工业大学','2017-07-06 12:00:00','211和985');

1 rows affected.

SQL> --向表education中插入记录4。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(15,'学士','西安建筑科技大学','2017-07-06 12:00:00','非211和985');

1 rows affected.

SQL> --向表education中插入记录5。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(18,'硕士','西安理工大学','2017-07-06 12:00:00','非211和985');

1 rows affected.

SQL> --向表education中插入记录6。
SQL> INSERT INTO education(staff_id,highest_degree,graduate_school,graduate_date,education_note) VALUES(20,'学士','北京师范大学','2017-07-06 12:00:00','211和985');

1 rows affected.

SQL> --提交事务。
SQL> COMMIT;

Succeed.

SQL> --创建分区索引。
SQL> drop table if exists idx_training;

Succeed.

SQL> CREATE INDEX idx_training ON education(staff_id ASC, highest_degree)
  2  LOCAL (PARTITION DOCTOR tablespace  TABLE_COMPRESS_TEST,
  3  PARTITION master tablespace  TABLE_COMPRESS_TEST,
  4  PARTITION undergraduate tablespace  TABLE_COMPRESS_TEST);

Succeed.

SQL> 
SQL> 
SQL> drop table if exists test_hash_hash;

Succeed.

SQL> create table test_hash_hash (
  2 id int,
  3 name varchar2(100)
  4 )  PARTITION BY HASH(id) SUBPARTITION BY HASH(name)
  5 (
  6 PARTITION PART_1 (SUBPARTITION P1_1, SUBPARTITION P1_2),
  7 PARTITION PART_2 (SUBPARTITION P2_1, SUBPARTITION P2_2)
  8 )  tablespace TABLE_COMPRESS_TEST;

Succeed.

SQL> 
SQL> --- 创建二级分区索引
SQL> drop index if exists index_local_sub_hash_compress ON TEST_HASH_HASH;

Succeed.

SQL> create index index_local_sub_hash_compress ON TEST_HASH_HASH (id)
  2 LOCAL (PARTITION PART_1  tablespace  TABLE_COMPRESS_MAP  
  3 				 (SUBPARTITION P1_1 tablespace  TABLE_COMPRESS_MAP,
  4 				  SUBPARTITION P1_2 tablespace  TABLE_COMPRESS_THREE
  5 				 ),
  6        PARTITION PART_2  tablespace  TABLE_COMPRESS_TEST
  7 	             (SUBPARTITION P2_1 tablespace  TABLE_COMPRESS_MAP,
  8 				  SUBPARTITION P2_2 tablespace  TABLE_COMPRESS_THREE
  9 				 )
 10       );

Succeed.

SQL> 
SQL> SHOW CREATE TABLE EDUCATION;

CREATE TABLE "EDUCATION"
(
  "STAFF_ID" BINARY_INTEGER NOT NULL,
  "HIGHEST_DEGREE" CHAR(8 BYTE),
  "GRADUATE_SCHOOL" VARCHAR(64 BYTE),
  "GRADUATE_DATE" DATE,
  "EDUCATION_NOTE" VARCHAR(70 BYTE)
)
PARTITION BY LIST ("HIGHEST_DEGREE")
(
    PARTITION DOCTOR VALUES('博士') TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION MASTER VALUES('硕士') TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION UNDERGRADUATE VALUES('学士') TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "IDX_TRAINING" ON "EDUCATION"("STAFF_ID", "HIGHEST_DEGREE")
LOCAL
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8;



SQL> SHOW CREATE TABLE TEST_HASH_HASH;

CREATE TABLE "TEST_HASH_HASH"
(
  "ID" BINARY_INTEGER,
  "NAME" VARCHAR(100 BYTE)
)
PARTITION BY HASH ("ID")
SUBPARTITION BY HASH ("NAME")
(
    PARTITION PART_1 TABLESPACE "TABLE_COMPRESS_TEST" INITRANS 2 PCTFREE 8 FORMAT ASF(
        SUBPARTITION P1_1 TABLESPACE "TABLE_COMPRESS_TEST", 
        SUBPARTITION P1_2 TABLESPACE "TABLE_COMPRESS_TEST"
    ),
    PARTITION PART_2 TABLESPACE "TABLE_COMPRESS_TEST" INITRANS 2 PCTFREE 8 FORMAT ASF(
        SUBPARTITION P2_1 TABLESPACE "TABLE_COMPRESS_TEST", 
        SUBPARTITION P2_2 TABLESPACE "TABLE_COMPRESS_TEST"
    )
)
TABLESPACE "TABLE_COMPRESS_TEST"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "INDEX_LOCAL_SUB_HASH_COMPRESS" ON "TEST_HASH_HASH"("ID")
LOCAL
TABLESPACE "TABLE_COMPRESS_TEST"
INITRANS 2
PCTFREE 8;



SQL> exp tables=EDUCATION,TEST_HASH_HASH file='index_partitioning.txt';
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = EDUCATION, TEST_HASH_HASH
-- FILE TYPE = TXT
-- DUMP FILE = index_partitioning.txt
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table CMBTEST.EDUCATION ...
  exporting DDL of CMBTEST.EDUCATION ...
  exporting data of CMBTEST.EDUCATION ...
    data exporting success, 6 rows are dumped.

  exporting indexes on CMBTEST.EDUCATION ...
  exporting constraints on CMBTEST.EDUCATION ...

exporting table CMBTEST.TEST_HASH_HASH ...
  exporting DDL of CMBTEST.TEST_HASH_HASH ...
  exporting data of CMBTEST.TEST_HASH_HASH ...
    data exporting success, 0 rows are dumped.

  exporting indexes on CMBTEST.TEST_HASH_HASH ...
  exporting constraints on CMBTEST.TEST_HASH_HASH ...

Logical export succeeded.

SQL> imp tables=EDUCATION,TEST_HASH_HASH file='index_partitioning.txt';
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = EDUCATION, TEST_HASH_HASH
-- DUMP FILE = index_partitioning.txt
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 6 rows are loaded.
Logical import succeeded.

SQL> 
SQL> exp tables=EDUCATION,TEST_HASH_HASH file='index_partitioning.bin' consistent=y filetype=bin;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = EDUCATION, TEST_HASH_HASH
-- FILE TYPE = BIN
-- DUMP FILE = index_partitioning.bin
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = Y
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table CMBTEST.EDUCATION ...
  exporting DDL of CMBTEST.EDUCATION ...
  exporting data of CMBTEST.EDUCATION ...
    data exporting success, 6 rows are dumped.

  exporting indexes on CMBTEST.EDUCATION ...
  exporting constraints on CMBTEST.EDUCATION ...

exporting table CMBTEST.TEST_HASH_HASH ...
  exporting DDL of CMBTEST.TEST_HASH_HASH ...
  exporting data of CMBTEST.TEST_HASH_HASH ...
    data exporting success, 0 rows are dumped.

  exporting indexes on CMBTEST.TEST_HASH_HASH ...
  exporting constraints on CMBTEST.TEST_HASH_HASH ...

Logical export succeeded.

SQL> imp tables=EDUCATION,TEST_HASH_HASH file='index_partitioning.bin' filetype=bin;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = EDUCATION, TEST_HASH_HASH
-- DUMP FILE = index_partitioning.bin
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema CMBTEST ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema CMBTEST ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema CMBTEST ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema CMBTEST ,total number : 2 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    EDUCATION                                                        6                   

  Importing foreign key of schema CMBTEST ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema CMBTEST ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema CMBTEST ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema CMBTEST ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema CMBTEST ...
    Package importing success, 0 rows are loaded.

data importing success, 6 rows are loaded.
Logical import succeeded.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop table if exists EDUCATION;

Succeed.

SQL> drop table if exists TEST_HASH_HASH;

Succeed.

SQL> drop user if exists CMBTEST cascade;

Succeed.

SQL> drop TABLESPACE TABLE_COMPRESS_TEST INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> drop TABLESPACE TABLE_COMPRESS_MAP INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> drop TABLESPACE TABLE_COMPRESS_THREE INCLUDING CONTENTS AND DATAFILES;

Succeed.

SQL> 
SQL> --number2
SQL> drop user if exists test_data;

Succeed.

SQL> create user test_data identified by 'Changeme_123';

Succeed.

SQL> grant dba to test_data;

Succeed.

SQL> conn test_data/Changeme_123@127.0.0.1:1611

connected.

SQL> 
SQL> drop table if exists number2_test;

Succeed.

SQL> CREATE TABLE  number2_test(
  2      COL_1 real,
  3      COL_2 double,
  4      COL_3 float,
  5      COL_4 number2(12,6),
  6      COL_5 number2,
  7      COL_6 number2
  8 );

Succeed.

SQL> begin
  2     for i in 1..10 loop
  3       insert into number2_test values(
  4       i+3.1415926,
  5       i+445.255,
  6       3.1415926-i*2,
  7       98*0.99*i, 
  8       99*1.01*i,
  9       -98*0.99*i
 10       );
 11       commit;
 12     end loop;
 13 end;
 14 /

PL/SQL procedure successfully completed.

SQL> select (select COL_4||dummy from sys_dummy) from number2_test order by COL_4 desc limit 2;

(SELECT COL_4||DUMMY FROM SYS_DUMMY)                            
----------------------------------------------------------------
970.2X                                                          
873.18X                                                         

2 rows fetched.

SQL> select (select COL_3||dummy from sys_dummy) from number2_test order by COL_3;

(SELECT COL_3||DUMMY FROM SYS_DUMMY)
------------------------------------
-16.8584074X                        
-14.8584074X                        
-12.8584074X                        
-10.8584074X                        
-8.8584074X                         
-6.8584074X                         
-4.8584074X                         
-2.8584074X                         
-0.8584074X                         
1.1415926X                          

10 rows fetched.

SQL> 
SQL> exp tables=number2_test file="number2_txt.dmp" filetype=txt;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER2_TEST
-- FILE TYPE = TXT
-- DUMP FILE = number2_txt.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_DATA.NUMBER2_TEST ...
  exporting DDL of TEST_DATA.NUMBER2_TEST ...
  exporting data of TEST_DATA.NUMBER2_TEST ...
    data exporting success, 10 rows are dumped.

  exporting indexes on TEST_DATA.NUMBER2_TEST ...
  exporting constraints on TEST_DATA.NUMBER2_TEST ...

Logical export succeeded.

SQL> drop table if exists number2_test;

Succeed.

SQL> imp tables=number2_test file="number2_txt.dmp" filetype=txt;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER2_TEST
-- DUMP FILE = number2_txt.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 10 rows are loaded.
Logical import succeeded.

SQL> select (select COL_4||dummy from sys_dummy) from number2_test order by COL_4 desc limit 2;

(SELECT COL_4||DUMMY FROM SYS_DUMMY)                            
----------------------------------------------------------------
970.2X                                                          
873.18X                                                         

2 rows fetched.

SQL> select (select COL_3||dummy from sys_dummy) from number2_test order by COL_3;

(SELECT COL_3||DUMMY FROM SYS_DUMMY)
------------------------------------
-16.8584074X                        
-14.8584074X                        
-12.8584074X                        
-10.8584074X                        
-8.8584074X                         
-6.8584074X                         
-4.8584074X                         
-2.8584074X                         
-0.8584074X                         
1.1415926X                          

10 rows fetched.

SQL> 
SQL> exp tables=number2_test file="number2_bin.dmp" filetype=bin parallel=2;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER2_TEST
-- FILE TYPE = BIN
-- DUMP FILE = number2_bin.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 2
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_DATA.NUMBER2_TEST ...
  exporting DDL of TEST_DATA.NUMBER2_TEST ...
    data exporting success! 10 rows are dumped.
  exporting indexes on TEST_DATA.NUMBER2_TEST ...
  exporting constraints on TEST_DATA.NUMBER2_TEST ...

Logical export succeeded.

SQL> drop table if exists number2_test;

Succeed.

SQL> imp tables=number2_test file="number2_bin.dmp" filetype=bin parallel=2;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER2_TEST
-- DUMP FILE = number2_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 2
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TEST_DATA ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TEST_DATA ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TEST_DATA ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TEST_DATA ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    NUMBER2_TEST                                                     10                  

  Importing foreign key of schema TEST_DATA ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TEST_DATA ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema TEST_DATA ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TEST_DATA ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TEST_DATA ...
    Package importing success, 0 rows are loaded.

data importing success, 10 rows are loaded.
Logical import succeeded.

SQL> select (select COL_4||dummy from sys_dummy) from number2_test order by COL_4 desc limit 2;

(SELECT COL_4||DUMMY FROM SYS_DUMMY)                            
----------------------------------------------------------------
970.2X                                                          
873.18X                                                         

2 rows fetched.

SQL> select (select COL_3||dummy from sys_dummy) from number2_test order by COL_3;

(SELECT COL_3||DUMMY FROM SYS_DUMMY)
------------------------------------
-16.8584074X                        
-14.8584074X                        
-12.8584074X                        
-10.8584074X                        
-8.8584074X                         
-6.8584074X                         
-4.8584074X                         
-2.8584074X                         
-0.8584074X                         
1.1415926X                          

10 rows fetched.

SQL> 
SQL> dump table number2_test INTO FILE "number2_dump.txt";
10 rows dumped.

Dump TABLE successfully:
  10 rows are totally dumped.

SQL> truncate table number2_test;

Succeed.

SQL> LOAD DATA INFILE 'number2_dump.txt' INTO TABLE number2_test;
10 rows have been committed.

Complete the data load.
totally read rows: 10
     ignored rows: 0
      loaded rows: 10
   committed rows: 10
       error rows: 0
        skip rows: 0
SQL> select (select COL_4||dummy from sys_dummy) from number2_test order by COL_4 desc limit 2;

(SELECT COL_4||DUMMY FROM SYS_DUMMY)                            
----------------------------------------------------------------
970.2X                                                          
873.18X                                                         

2 rows fetched.

SQL> select (select COL_3||dummy from sys_dummy) from number2_test order by COL_3;

(SELECT COL_3||DUMMY FROM SYS_DUMMY)
------------------------------------
-16.8584074X                        
-14.8584074X                        
-12.8584074X                        
-10.8584074X                        
-8.8584074X                         
-6.8584074X                         
-4.8584074X                         
-2.8584074X                         
-0.8584074X                         
1.1415926X                          

10 rows fetched.

SQL> drop table if exists number2_test;

Succeed.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists test_data cascade;

Succeed.

SQL> 
SQL> ---fuzz DTS202106080FNBXKP1L00
SQL> drop user if exists cantiandba cascade;

Succeed.

SQL> CREATE USER cantiandba IDENTIFIED BY Changeme_123;

Succeed.

SQL> GRANT DBA TO cantiandba;

Succeed.

SQL> conn cantiandba/Changeme_123@127.0.0.1:1611

connected.

SQL> imp users=cantiandba file="./data/fuzz_test/export_bin.dmp" filetype=bin;
Parsing import options ... 
Verify options ...
  verify schema ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = CANTIANDBA
-- DUMP FILE = ./data/fuzz_test/export_bin.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N


Importing schema CANTIANDBA ...
  Importing sequence of schema CANTIANDBA ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema CANTIANDBA ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema CANTIANDBA ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema CANTIANDBA ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
ZS-00005: read row data failed!
ZS-00005: Load sub file failed !

CT-00520, Import error occur when check DML return code, detail: DML worker throwed error
Logical import failed.

SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists cantiandba cascade;

Succeed.

SQL> 
SQL> drop user if exists partition_user cascade;

Succeed.

SQL> CREATE USER partition_user IDENTIFIED BY Changeme_123;

Succeed.

SQL> GRANT DBA TO partition_user;

Succeed.

SQL> conn partition_user/Changeme_123@127.0.0.1:1611

connected.

SQL> drop table if exists EEE;

Succeed.

SQL> CREATE TABLE "EEE"
  2 (
  3   "ID" BINARY_INTEGER,
  4   "NAME" VARCHAR(20 BYTE)
  5 )
  6 PARTITION BY RANGE ("ID")
  7 INTERVAL(50)
  8 SUBPARTITION BY HASH ("NAME")
  9 (
 10     PARTITION P1 VALUES LESS THAN (50) TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
 11         SUBPARTITION P11 TABLESPACE "USERS",
 12         SUBPARTITION P12 TABLESPACE "USERS"
 13     ),
 14     PARTITION P2 VALUES LESS THAN (100) TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
 15         SUBPARTITION P21 TABLESPACE "USERS",
 16         SUBPARTITION P22 TABLESPACE "USERS"
 17     )
 18 );

Succeed.

SQL> CREATE INDEX "INDEX_100" ON "EEE"("ID", "NAME")
  2 LOCAL
  3       (
  4        PARTITION P1 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  5            SUBPARTITION P11 TABLESPACE "USERS",
  6            SUBPARTITION P12 TABLESPACE "USERS"
  7         ),
  8        PARTITION P2 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  9            SUBPARTITION P21 TABLESPACE "USERS",
 10            SUBPARTITION P22 TABLESPACE "USERS"
 11         )
 12       );

Succeed.

SQL> 
SQL> 
SQL> CREATE INDEX "INDEX_101" ON "EEE"("ID")
  2 LOCAL
  3       (
  4        PARTITION P1 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  5            SUBPARTITION P11 TABLESPACE "USERS",
  6            SUBPARTITION P12 TABLESPACE "USERS"
  7         ),
  8        PARTITION P2 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  9            SUBPARTITION P21 TABLESPACE "USERS",
 10            SUBPARTITION P22 TABLESPACE "USERS"
 11         )
 12       );

Succeed.

SQL> 
SQL> CREATE INDEX "INDEX_102" ON "EEE"("NAME")
  2 LOCAL
  3       (
  4        PARTITION P1 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  5            SUBPARTITION P11 TABLESPACE "USERS",
  6            SUBPARTITION P12 TABLESPACE "USERS"
  7         ),
  8        PARTITION P2 TABLESPACE "USERS" INITRANS 2 PCTFREE 8(
  9            SUBPARTITION P21 TABLESPACE "USERS",
 10            SUBPARTITION P22 TABLESPACE "USERS"
 11         )
 12       );

Succeed.

SQL> exp tables=% file='partitioning.txt';
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = ALL_TABLES
-- EXPORT OBJECTS = 
-- FILE TYPE = TXT
-- DUMP FILE = partitioning.txt
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

Reading table objects of PARTITION_USER

The order of exporting table is:
TABLE NAME                                                       LEVEL     
---------------------------------------------------------------- ----------
EEE                                                              1         

Exporting tables (scripts or data) of PARTITION_USER
exporting table PARTITION_USER.EEE ...
  exporting DDL of PARTITION_USER.EEE ...
  exporting data of PARTITION_USER.EEE ...
    data exporting success, 0 rows are dumped.

  exporting indexes on PARTITION_USER.EEE ...
  exporting constraints on PARTITION_USER.EEE ...

Logical export succeeded.

SQL> imp tables=% file='partitioning.txt';
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = ALL_TABLES
-- IMPORT OBJECTS = 
-- DUMP FILE = partitioning.txt
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> drop table if exists EEE;

Succeed.

SQL> --number2 max_value
SQL> drop table if exists number2_test_overflow;

Succeed.

SQL> create table number2_test_overflow(id number2);

Succeed.

SQL> insert into number2_test_overflow values(cast('9.99999999999999999999999999999999999E+125' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('9.999999999999999999999999999999999999999E+125' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('-9.999999999999999999999999999999999999999E+125' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('9.999999999999999999999999999999999999999E+124' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('9.999999999999999999999999999999999999999E-130' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('-9.999999999999999999999999999999999999999E-130' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('9.999999999999999999999999999999999999999E-131' as number2));

1 rows affected.

SQL> insert into number2_test_overflow values(cast('9.99999999999999999999999999999E+125' as number2));

1 rows affected.

SQL> commit;

Succeed.

SQL> select * from  number2_test_overflow;

ID                                      
----------------------------------------
########################################
########################################
########################################
1.000000000000000000000000000000000E+125
1.000000000000000000000000000000000E-129
-1.00000000000000000000000000000000E-129
0                                       
9.999999999999999999999999999990000E+125

8 rows fetched.

SQL> EXP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_1.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- FILE TYPE = TXT
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting data of PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
    data exporting success, 8 rows are dumped.

  exporting indexes on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...

Logical export succeeded.

SQL> EXP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_2.dat" filetype=BIN;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- FILE TYPE = BIN
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_2.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting data of PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
    data exporting success, 8 rows are dumped.

  exporting indexes on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...

Logical export succeeded.

SQL> EXP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_3.dat" filetype=txt parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- FILE TYPE = TXT
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_3.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting indexes on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER2_TEST_OVERFLOW ...

Logical export succeeded.

SQL> drop table number2_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_1.dmp";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> select * from  number2_test_overflow where id = 0;

ID                                      
----------------------------------------
0                                       

1 rows fetched.

SQL> drop table number2_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_2.dat" filetype=BIN;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_2.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema PARTITION_USER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema PARTITION_USER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema PARTITION_USER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema PARTITION_USER ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    NUMBER2_TEST_OVERFLOW                                            8                   

  Importing foreign key of schema PARTITION_USER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema PARTITION_USER ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema PARTITION_USER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema PARTITION_USER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema PARTITION_USER ...
    Package importing success, 0 rows are loaded.

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> select * from  number2_test_overflow where id = 0;

ID                                      
----------------------------------------
0                                       

1 rows fetched.

SQL> drop table number2_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER2_TEST_OVERFLOW FILE = "./data/NUMBER2_TEST_OVERFLOW_3.dat" filetype=txt parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER2_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER2_TEST_OVERFLOW_3.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 9 rows are loaded.
Logical import succeeded.

SQL> select * from number2_test_overflow;

ID                                      
----------------------------------------
########################################
########################################
########################################
1.000000000000000000000000000000000E+125
1.000000000000000000000000000000000E-129
-1.00000000000000000000000000000000E-129
0                                       
9.999999999999999999999999999990000E+125

8 rows fetched.

SQL> drop table if exists number2_test_overflow;

Succeed.

SQL> --number max_value
SQL> drop table if exists number_test_overflow;

Succeed.

SQL> create table number_test_overflow(id number);

Succeed.

SQL> insert into number_test_overflow values(cast('9.99999999999999999999999999999999999E+127' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('9.999999999999999999999999999999999999999E+127' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('-9.999999999999999999999999999999999999999E+127' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('9.999999999999999999999999999999999999999E+126' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('9.999999999999999999999999999999999999999E-127' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('-9.999999999999999999999999999999999999999E-127' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('9.999999999999999999999999999999999999999E-128' as number));

1 rows affected.

SQL> insert into number_test_overflow values(cast('9.99999999999999999999999999999E+127' as number));

1 rows affected.

SQL> commit;

Succeed.

SQL> select * from  number_test_overflow;

ID                                      
----------------------------------------
1.000000000000000000000000000000000E+128
1.000000000000000000000000000000000E+128
-1.00000000000000000000000000000000E+128
1.000000000000000000000000000000000E+127
1.000000000000000000000000000000000E-126
-1.00000000000000000000000000000000E-126
0                                       
9.999999999999999999999999999990000E+127

8 rows fetched.

SQL> EXP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_1.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- FILE TYPE = TXT
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting data of PARTITION_USER.NUMBER_TEST_OVERFLOW ...
    data exporting success, 8 rows are dumped.

  exporting indexes on PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER_TEST_OVERFLOW ...

Logical export succeeded.

SQL> EXP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_2.dat" filetype=BIN;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- FILE TYPE = BIN
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_2.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting data of PARTITION_USER.NUMBER_TEST_OVERFLOW ...
    data exporting success, 8 rows are dumped.

  exporting indexes on PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER_TEST_OVERFLOW ...

Logical export succeeded.

SQL> EXP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_3.dat" filetype=txt parallel=4;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- FILE TYPE = TXT
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_3.dat
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 4
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting DDL of PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting indexes on PARTITION_USER.NUMBER_TEST_OVERFLOW ...
  exporting constraints on PARTITION_USER.NUMBER_TEST_OVERFLOW ...

Logical export succeeded.

SQL> drop table number_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_1.dmp";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> select * from  number_test_overflow limit 1;

ID                                      
----------------------------------------
9.999999900000000000000000000000000E+127

1 rows fetched.

SQL> drop table number_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_2.dat" filetype=BIN;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_2.dat
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema PARTITION_USER ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema PARTITION_USER ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema PARTITION_USER ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema PARTITION_USER ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    NUMBER_TEST_OVERFLOW                                             8                   

  Importing foreign key of schema PARTITION_USER ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema PARTITION_USER ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema PARTITION_USER ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema PARTITION_USER ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema PARTITION_USER ...
    Package importing success, 0 rows are loaded.

data importing success, 8 rows are loaded.
Logical import succeeded.

SQL> select * from  number_test_overflow limit 3;

ID                                      
----------------------------------------
1.000000000000000000000000000000000E+128
1.000000000000000000000000000000000E+128
-1.00000000000000000000000000000000E+128

3 rows fetched.

SQL> drop table number_test_overflow;

Succeed.

SQL> IMP TABLES = NUMBER_TEST_OVERFLOW FILE = "./data/NUMBER_TEST_OVERFLOW_3.dat" filetype=txt parallel=4;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = NUMBER_TEST_OVERFLOW
-- DUMP FILE = ./data/NUMBER_TEST_OVERFLOW_3.dat
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 4
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 9 rows are loaded.
Logical import succeeded.

SQL> select * from  number_test_overflow;

ID                                      
----------------------------------------
9.999999900000000000000000000000000E+127
9.999999900000000000000000000000000E+127
-9.99999990000000000000000000000000E+127
1.000000000000000000000000000000000E+127
1.000000000000000000000000000000000E-126
-1.00000000000000000000000000000000E-126
0                                       
9.999999900000000000000000000000000E+127

8 rows fetched.

SQL> drop table if exists number_test_overflow;

Succeed.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists partition_user cascade;

Succeed.

SQL> 
SQL> -- test for interval autoextend
SQL> create user test_interval_partition_exp1 identified by database_123;

Succeed.

SQL> grant dba to test_interval_partition_exp1;

Succeed.

SQL> 
SQL> conn test_interval_partition_exp1/database_123@127.0.0.1:1611

connected.

SQL> 
SQL> drop table if exists TBL_INTERVAL_CSF_FIRST;

Succeed.

SQL> create table tbl_interval_csf_first(
  2 col_int int primary key,
  3 col_number1 number,
  4 col_number2 number(20,2),
  5 col_number3 number(20,-3),
  6 col_number4 number(3,10),
  7 col_number5 number(38,7),
  8 col_numeric numeric
  9 )
 10 partition by range(col_number1) interval (10)
 11 (
 12   partition p_interval_01 values less than (10) ,
 13   partition p_interval_02 values less than (20),
 14   partition p_interval_03 values less than (30)
 15  );

Succeed.

SQL> create index INDEX_TBL_INTERVAL_CSF_FIRST_01 on TBL_INTERVAL_CSF_FIRST(col_number1) LOCAL;

Succeed.

SQL> 
SQL> 
SQL> insert into TBL_INTERVAL_CSF_FIRST(col_int,col_number1,col_number2,col_number3,col_number4) values (1,1,1,1,0);

1 rows affected.

SQL> CREATE or replace procedure proc_insert(tname varchar,startall int,endall int) as
  2 sqlst varchar(500);
  3 BEGIN
  4   FOR i IN startall..endall LOOP
  5                 sqlst := 'insert into ' || tname ||'(col_int,col_number1,col_number2,col_number3,col_number4)  select
  6 			    col_int+'||i||',col_number1||'||i||',col_number2||'||i||',col_number3'||',0 from '||tname|| ' where col_int=1';
  7         execute immediate sqlst;
  8   END LOOP;
  9 END;
 10 /

Succeed.

SQL> exec proc_insert('TBL_INTERVAL_CSF_FIRST',1,99);

PL/SQL procedure successfully completed.

SQL> commit;

Succeed.

SQL> 
SQL> show create table tbl_interval_csf_first;

CREATE TABLE "TBL_INTERVAL_CSF_FIRST"
(
  "COL_INT" BINARY_INTEGER NOT NULL,
  "COL_NUMBER1" NUMBER,
  "COL_NUMBER2" NUMBER(20, 2),
  "COL_NUMBER3" NUMBER(20, -3),
  "COL_NUMBER4" NUMBER(3, 10),
  "COL_NUMBER5" NUMBER(38, 7),
  "COL_NUMERIC" NUMBER
)
PARTITION BY RANGE ("COL_NUMBER1")
INTERVAL(10)
(
    PARTITION P_INTERVAL_01 VALUES LESS THAN (10) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_02 VALUES LESS THAN (20) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_03 VALUES LESS THAN (30) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "INDEX_TBL_INTERVAL_CSF_FIRST_01" ON "TBL_INTERVAL_CSF_FIRST"("COL_NUMBER1")
LOCAL
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8;
ALTER TABLE "TBL_INTERVAL_CSF_FIRST" ADD PRIMARY KEY("COL_INT");



SQL> exp tables=tbl_interval_csf_first;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- FILE TYPE = TXT
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
    data exporting success, 100 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...

Logical export succeeded.

SQL> imp tables=tbl_interval_csf_first;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 100 rows are loaded.
Logical import succeeded.

SQL> 
SQL> -- test for interval not autoextend
SQL> drop table if exists TBL_INTERVAL_CSF_FIRST;

Succeed.

SQL> create table tbl_interval_csf_first(
  2 col_int int primary key,
  3 col_number1 number,
  4 col_number2 number(20,2),
  5 col_number3 number(20,-3),
  6 col_number4 number(3,10),
  7 col_number5 number(38,7),
  8 col_numeric numeric
  9 )
 10 partition by range(col_number1) interval (10)
 11 (
 12   partition p_interval_01 values less than (10) ,
 13   partition p_interval_02 values less than (20),
 14   partition p_interval_03 values less than (30)
 15  );

Succeed.

SQL> create index INDEX_TBL_INTERVAL_CSF_FIRST_01 on TBL_INTERVAL_CSF_FIRST(col_number1) LOCAL;

Succeed.

SQL> 
SQL> 
SQL> insert into TBL_INTERVAL_CSF_FIRST(col_int,col_number1,col_number2,col_number3,col_number4) values (1,1,1,1,0);

1 rows affected.

SQL> CREATE or replace procedure proc_insert(tname varchar,startall int,endall int) as
  2 sqlst varchar(500);
  3 BEGIN
  4   FOR i IN startall..endall LOOP
  5                 sqlst := 'insert into ' || tname ||'(col_int,col_number1,col_number2,col_number3,col_number4)  select
  6 			    col_int+'||i||',col_number1||'||i||',col_number2||'||i||',col_number3'||',0 from '||tname|| ' where col_int=1';
  7         execute immediate sqlst;
  8   END LOOP;
  9 END;
 10 /

Succeed.

SQL> exec proc_insert('TBL_INTERVAL_CSF_FIRST',1,8);

PL/SQL procedure successfully completed.

SQL> commit;

Succeed.

SQL> 
SQL> show create table tbl_interval_csf_first;

CREATE TABLE "TBL_INTERVAL_CSF_FIRST"
(
  "COL_INT" BINARY_INTEGER NOT NULL,
  "COL_NUMBER1" NUMBER,
  "COL_NUMBER2" NUMBER(20, 2),
  "COL_NUMBER3" NUMBER(20, -3),
  "COL_NUMBER4" NUMBER(3, 10),
  "COL_NUMBER5" NUMBER(38, 7),
  "COL_NUMERIC" NUMBER
)
PARTITION BY RANGE ("COL_NUMBER1")
INTERVAL(10)
(
    PARTITION P_INTERVAL_01 VALUES LESS THAN (10) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_02 VALUES LESS THAN (20) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_03 VALUES LESS THAN (30) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "INDEX_TBL_INTERVAL_CSF_FIRST_01" ON "TBL_INTERVAL_CSF_FIRST"("COL_NUMBER1")
LOCAL
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8;
ALTER TABLE "TBL_INTERVAL_CSF_FIRST" ADD PRIMARY KEY("COL_INT");



SQL> exp tables=tbl_interval_csf_first;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- FILE TYPE = TXT
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
    data exporting success, 9 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...

Logical export succeeded.

SQL> imp tables=tbl_interval_csf_first;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 9 rows are loaded.
Logical import succeeded.

SQL> 
SQL> DROP TABLE IF EXISTS "TBL_INTERVAL_CSF_FIRST";

Succeed.

SQL> CREATE TABLE "TBL_INTERVAL_CSF_FIRST"
  2 (
  3   "COL_INT" BINARY_INTEGER NOT NULL,
  4   "COL_NUMBER1" NUMBER,
  5   "COL_NUMBER2" NUMBER(20, 2),
  6   "COL_NUMBER3" NUMBER(20, -3),
  7   "COL_NUMBER4" NUMBER(3, 10),
  8   "COL_NUMBER5" NUMBER(38, 7),
  9   "COL_NUMERIC" NUMBER
 10 )
 11 PARTITION BY RANGE ("COL_NUMBER1")
 12 INTERVAL(10)
 13 (
 14     PARTITION P_INTERVAL_09 VALUES LESS THAN (10) TABLESPACE "USERS" INITRANS 2 PCTFREE 8,
 15     PARTITION P_INTERVAL_08 VALUES LESS THAN (20) TABLESPACE "USERS" INITRANS 2 PCTFREE 8,
 16     PARTITION P_INTERVAL_07 VALUES LESS THAN (30) TABLESPACE "USERS" INITRANS 2 PCTFREE 8
 17 )
 18 TABLESPACE "USERS"
 19 INITRANS 2
 20 MAXTRANS 255
 21 PCTFREE 8;

Succeed.

SQL> INSERT INTO "TBL_INTERVAL_CSF_FIRST"("COL_INT","COL_NUMBER1") VALUES(1,9),(2,19),(3,29);

3 rows affected.

SQL> COMMIT;

Succeed.

SQL> CREATE INDEX "INDEX_TBL_INTERVAL_CSF_FIRST_01" ON "TBL_INTERVAL_CSF_FIRST"("COL_NUMBER1")
  2 LOCAL
  3       (
  4        PARTITION P_INTERVAL_19 TABLESPACE "USERS" INITRANS 2 PCTFREE 8,
  5        PARTITION P_INTERVAL_18 TABLESPACE "USERS" INITRANS 2 PCTFREE 8,
  6        PARTITION P_INTERVAL_17 TABLESPACE "USERS" INITRANS 2 PCTFREE 8
  7       )
  8 TABLESPACE "USERS"
  9 INITRANS 2
 10 PCTFREE 8;

Succeed.

SQL> ALTER TABLE "TBL_INTERVAL_CSF_FIRST" ADD PRIMARY KEY("COL_INT");

Succeed.

SQL> 
SQL> show create table TBL_INTERVAL_CSF_FIRST;

CREATE TABLE "TBL_INTERVAL_CSF_FIRST"
(
  "COL_INT" BINARY_INTEGER NOT NULL,
  "COL_NUMBER1" NUMBER,
  "COL_NUMBER2" NUMBER(20, 2),
  "COL_NUMBER3" NUMBER(20, -3),
  "COL_NUMBER4" NUMBER(3, 10),
  "COL_NUMBER5" NUMBER(38, 7),
  "COL_NUMERIC" NUMBER
)
PARTITION BY RANGE ("COL_NUMBER1")
INTERVAL(10)
(
    PARTITION P_INTERVAL_09 VALUES LESS THAN (10) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_08 VALUES LESS THAN (20) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_07 VALUES LESS THAN (30) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "INDEX_TBL_INTERVAL_CSF_FIRST_01" ON "TBL_INTERVAL_CSF_FIRST"("COL_NUMBER1")
LOCAL
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8;
ALTER TABLE "TBL_INTERVAL_CSF_FIRST" ADD PRIMARY KEY("COL_INT");



SQL> exp tables=TBL_INTERVAL_CSF_FIRST;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- FILE TYPE = TXT
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
    data exporting success, 3 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TBL_INTERVAL_CSF_FIRST ...

Logical export succeeded.

SQL> imp tables=TBL_INTERVAL_CSF_FIRST;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TBL_INTERVAL_CSF_FIRST
-- DUMP FILE = EXPDAT.DMP
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 3 rows are loaded.
Logical import succeeded.

SQL> --20210731
SQL> drop table if exists temp_0731;

Succeed.

SQL> create table temp_0731(f1 int);

Succeed.

SQL> create index idx_temp_0731 on temp_0731(f1) reverse;

Succeed.

SQL> show create table temp_0731;

CREATE TABLE "TEMP_0731"
(
  "F1" BINARY_INTEGER
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "IDX_TEMP_0731" ON "TEMP_0731"("F1")
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8
REVERSE;



SQL> drop table temp_0731;

Succeed.

SQL> CREATE TABLE "TEMP_0731"
  2 (
  3   "F1" BINARY_INTEGER
  4 )
  5 TABLESPACE "USERS"
  6 INITRANS 2
  7 MAXTRANS 255
  8 PCTFREE 8
  9 FORMAT ASF;

Succeed.

SQL> CREATE INDEX "IDX_TEMP_0731" ON "TEMP_0731"("F1")
  2 TABLESPACE "USERS"
  3 INITRANS 2
  4 PCTFREE 8
  5 REVERSE;

Succeed.

SQL> drop table TEMP_0731;

Succeed.

SQL> 
SQL> --20210815
SQL> drop table if exists temp0815;

Succeed.

SQL> create table temp0815(f1 int primary key reverse, f2 int);

CT-00601, [1:42]Sql syntax error: constraint expected but reverse found
SQL> show create table temp0815;

CT-00828, table TEST_INTERVAL_PARTITION_EXP1.TEMP0815 does not exist
SHOW CREATE TABLE failed.

SQL> drop table temp0815;

CT-00843, The table or view TEST_INTERVAL_PARTITION_EXP1.TEMP0815 does not exist.
SQL> create table temp0815(f1 int , f2 int, primary key(f1) reverse);

CT-00601, [1:56]Sql syntax error: unexpected text reverse
SQL> show create table temp0815;

CT-00828, table TEST_INTERVAL_PARTITION_EXP1.TEMP0815 does not exist
SHOW CREATE TABLE failed.

SQL> drop table temp0815;

CT-00843, The table or view TEST_INTERVAL_PARTITION_EXP1.TEMP0815 does not exist.
SQL> create table temp0815(f1 int, f2 int);

Succeed.

SQL> alter table temp0815 add constraint pk_temp0815 primary key (f1) reverse;

Succeed.

SQL> show create table temp0815;

CREATE TABLE "TEMP0815"
(
  "F1" BINARY_INTEGER NOT NULL,
  "F2" BINARY_INTEGER
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
ALTER TABLE "TEMP0815" ADD CONSTRAINT "PK_TEMP0815" PRIMARY KEY("F1") REVERSE;



SQL> drop table temp0815;

Succeed.

SQL> create table temp0815(f1 int, f2 int);

Succeed.

SQL> create index idx_temp0815 on temp0815(f1) reverse;

Succeed.

SQL> alter table temp0815 add constraint pk_temp0815 primary key (f1) using index idx_temp0815;

Succeed.

SQL> create unique index temp_0815_uidx on temp0815(f2) reverse;

Succeed.

SQL> show create table temp0815;

CREATE TABLE "TEMP0815"
(
  "F1" BINARY_INTEGER NOT NULL,
  "F2" BINARY_INTEGER
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "IDX_TEMP0815" ON "TEMP0815"("F1")
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8
REVERSE;
CREATE UNIQUE INDEX "TEMP_0815_UIDX" ON "TEMP0815"("F2")
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8
REVERSE;
ALTER TABLE "TEMP0815" ADD CONSTRAINT "PK_TEMP0815" PRIMARY KEY("F1");



SQL> drop table temp0815;

Succeed.

SQL> create table temp0815 (f1 int check(f1 > 1));

Succeed.

SQL> drop table if exists temp0815_1;

Succeed.

SQL> create table temp0815_1 (f1 int);

Succeed.

SQL> alter table temp0815_1 add constraint chk_0813 check(f1 > 2);

Succeed.

SQL> exp tables = temp0815,temp0815_1 file = "TBL_INDEX_WITH_NOLOGGING_1.dmp"  quote_names=N;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TEMP0815, TEMP0815_1
-- FILE TYPE = TXT
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = N
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...

exporting table TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...

Logical export succeeded.

SQL> imp file="TBL_INDEX_WITH_NOLOGGING_1.dmp";
Parsing import options ... 
Verify options ...
  default to import current schema: TEST_INTERVAL_PARTITION_EXP1
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = TEST_INTERVAL_PARTITION_EXP1
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> exp tables = temp0815,temp0815_1 file = "TBL_INDEX_WITH_NOLOGGING_1.dmp"  quote_names=Y;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TEMP0815, TEMP0815_1
-- FILE TYPE = TXT
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TEMP0815 ...

exporting table TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting DDL of TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting data of TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
    data exporting success, 0 rows are dumped.

  exporting indexes on TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...
  exporting constraints on TEST_INTERVAL_PARTITION_EXP1.TEMP0815_1 ...

Logical export succeeded.

SQL> imp file="TBL_INDEX_WITH_NOLOGGING_1.dmp";
Parsing import options ... 
Verify options ...
  default to import current schema: TEST_INTERVAL_PARTITION_EXP1
Starting import ...
Preparing to import ...
-- IMPORT TYPE = SCHEMA
-- IMPORT OBJECTS = TEST_INTERVAL_PARTITION_EXP1
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 0 rows are loaded.
Logical import succeeded.

SQL> drop table temp0815;

Succeed.

SQL> drop table temp0815_1;

Succeed.

SQL> create table temp0815(f1 int, f2 int) partition by range(f1) (partition p1 values less than (1));

Succeed.

SQL> alter table temp0815 add constraint pk_temp0815 primary key (f1) reverse;

Succeed.

SQL> create index temp0815_idx002 on temp0815(f2) local reverse;

Succeed.

SQL> show create table temp0815;

CREATE TABLE "TEMP0815"
(
  "F1" BINARY_INTEGER NOT NULL,
  "F2" BINARY_INTEGER
)
PARTITION BY RANGE ("F1")
(
    PARTITION P1 VALUES LESS THAN (1) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "TEMP0815_IDX002" ON "TEMP0815"("F2")
LOCAL
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8
REVERSE;
ALTER TABLE "TEMP0815" ADD CONSTRAINT "PK_TEMP0815" PRIMARY KEY("F1") REVERSE;



SQL> drop table temp0815;

Succeed.

SQL> --AR.SR.20210623200704.001.004
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists test_index cascade;

Succeed.

SQL> create user test_index identified by Changeme_123;

Succeed.

SQL> grant dba to test_index;

Succeed.

SQL> 
SQL> conn test_index/Changeme_123@127.0.0.1:1611

connected.

SQL> drop table if exists TBL_INDEX_WITH_NOLOGGING;

Succeed.

SQL> create table TBL_INDEX_WITH_NOLOGGING(
  2 col_int int primary key,
  3 col_number1 number,
  4 col_number2 number(20,2),
  5 col_numeric numeric,
  6 col_varchar varchar(20)
  7 )
  8 partition by range(col_number1) interval (10)
  9 (
 10   partition p_interval_01 values less than (10) ,
 11   partition p_interval_02 values less than (20),
 12   partition p_interval_03 values less than (30)
 13  );

Succeed.

SQL> 
SQL> create index INDEX_WITHOUT_NOLOGGING on TBL_INDEX_WITH_NOLOGGING(col_number1);

Succeed.

SQL> create index INDEX_WITH_NOLOGGING on TBL_INDEX_WITH_NOLOGGING(col_varchar) NOLOGGING;

Succeed.

SQL> INSERT INTO TBL_INDEX_WITH_NOLOGGING VALUES(1, 9, 2323, 22, 'TEST1');

1 rows affected.

SQL> INSERT INTO TBL_INDEX_WITH_NOLOGGING VALUES(2, 15, 3434, 22, 'TEST2');

1 rows affected.

SQL> INSERT INTO TBL_INDEX_WITH_NOLOGGING VALUES(3, 21, 4545, 22, 'TEST3');

1 rows affected.

SQL> INSERT INTO TBL_INDEX_WITH_NOLOGGING VALUES(4, 33, 6767, 22, 'TEST4');

1 rows affected.

SQL> COMMIT;

Succeed.

SQL> 
SQL> show create table TBL_INDEX_WITH_NOLOGGING;

CREATE TABLE "TBL_INDEX_WITH_NOLOGGING"
(
  "COL_INT" BINARY_INTEGER NOT NULL,
  "COL_NUMBER1" NUMBER,
  "COL_NUMBER2" NUMBER(20, 2),
  "COL_NUMERIC" NUMBER,
  "COL_VARCHAR" VARCHAR(20 BYTE)
)
PARTITION BY RANGE ("COL_NUMBER1")
INTERVAL(10)
(
    PARTITION P_INTERVAL_01 VALUES LESS THAN (10) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_02 VALUES LESS THAN (20) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF,
    PARTITION P_INTERVAL_03 VALUES LESS THAN (30) TABLESPACE "USERS" INITRANS 2 PCTFREE 8 FORMAT ASF
)
TABLESPACE "USERS"
INITRANS 2
MAXTRANS 255
PCTFREE 8
FORMAT ASF;
CREATE INDEX "INDEX_WITHOUT_NOLOGGING" ON "TBL_INDEX_WITH_NOLOGGING"("COL_NUMBER1")
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8;
CREATE INDEX "INDEX_WITH_NOLOGGING" ON "TBL_INDEX_WITH_NOLOGGING"("COL_VARCHAR")
TABLESPACE "USERS"
INITRANS 2
PCTFREE 8
NOLOGGING;
ALTER TABLE "TBL_INDEX_WITH_NOLOGGING" ADD PRIMARY KEY("COL_INT");



SQL> EXP TABLES = TBL_INDEX_WITH_NOLOGGING FILE = "TBL_INDEX_WITH_NOLOGGING_1.dmp";
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TBL_INDEX_WITH_NOLOGGING
-- FILE TYPE = TXT
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting DDL of TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting data of TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
    data exporting success, 4 rows are dumped.

  exporting indexes on TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting constraints on TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...

Logical export succeeded.

SQL> drop table TBL_INDEX_WITH_NOLOGGING;

Succeed.

SQL> IMP TABLES = TBL_INDEX_WITH_NOLOGGING FILE = "TBL_INDEX_WITH_NOLOGGING_1.dmp";
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TBL_INDEX_WITH_NOLOGGING
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_1.dmp
-- LOG FILE = 
-- FILE TYPE = TXT
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> SELECT COUNT(*) FROM TBL_INDEX_WITH_NOLOGGING;

COUNT(*)            
--------------------
4                   

1 rows fetched.

SQL> 
SQL> EXP TABLES = TBL_INDEX_WITH_NOLOGGING FILE = "TBL_INDEX_WITH_NOLOGGING_2.dmp" FILETYPE=BIN;
Parsing export options ... 
Verify options ...
  verify tables ...
Starting export ...
Preparing to export ...
-- EXPORT TYPE = TABLE
-- EXPORT OBJECTS = TBL_INDEX_WITH_NOLOGGING
-- FILE TYPE = BIN
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_2.dmp
-- LOG FILE = 
-- QUERY = ""
-- COMPRESS = N
-- CONSISTENT = N
-- CONTENT_MODE = ALL
-- SKIP_COMMENTS = N
-- FORCE = N
-- SKIP_ADD_DROP_TABLE = N
-- SKIP_TRIGGERS = N
-- QUOTE_NAMES = Y
-- TABLESPACE = N
-- COMMIT_BATCH = 1000
-- INSERT_BATCH = 1
-- FEEDBACK = 10000
-- PARALLEL = 0
-- TENANT = N
-- CREATE_USER = N
-- ROLE = N
-- GRANT = N
-- WITH_CR_MODE = N
-- WITH_FORMAT_CSF = Y
-- INDEX_PARTITIONS = N

exporting table TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting DDL of TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting data of TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
    data exporting success, 4 rows are dumped.

  exporting indexes on TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...
  exporting constraints on TEST_INDEX.TBL_INDEX_WITH_NOLOGGING ...

Logical export succeeded.

SQL> drop table TBL_INDEX_WITH_NOLOGGING;

Succeed.

SQL> IMP TABLES = TBL_INDEX_WITH_NOLOGGING FILE = "TBL_INDEX_WITH_NOLOGGING_2.dmp" FILETYPE=BIN;
Parsing import options ... 
Verify options ...
  verify tables ...
Starting import ...
Preparing to import ...
-- IMPORT TYPE = TABLE
-- IMPORT OBJECTS = TBL_INDEX_WITH_NOLOGGING
-- DUMP FILE = TBL_INDEX_WITH_NOLOGGING_2.dmp
-- LOG FILE = 
-- FILE TYPE = BIN
-- SHOW = N
-- FEEDBACK = 10000
-- PARALLEL = 1
-- DDL_PARALLEL = 1
-- CONTENT_MODE = ALL
-- IGNORE = N
-- CREATE_USER = N
-- TIMING = OFF
-- BATCH_COUNT = 10000
-- DISABLE_TRIGGER = Y
-- NOLOGGING = N

  Importing sequence of schema TEST_INDEX ...
    Sequence importing success, 0 rows are loaded.
  Importing profile of schema TEST_INDEX ...
    Profile importing success, 0 rows are loaded.
  Importing type of schema TEST_INDEX ...
    Type importing success, 0 rows are loaded.

  Importing tables of schema TEST_INDEX ,total number : 1 ...
    The order of importing table is:
    TABLE NAME                                                       RECORD NUMBER 
    ---------------------------------------------------------------- --------------
    TBL_INDEX_WITH_NOLOGGING                                         4                   

  Importing foreign key of schema TEST_INDEX ...
    Foreign key importing success, 0 rows are loaded.

  Importing fuction/procedure/trigger of schema TEST_INDEX ...
    Fuction/procedure/trigger importing success, 0 rows are loaded.

  Importing view of schema TEST_INDEX ...
    View importing success, 0 rows are loaded.

  Importing synonym of schema TEST_INDEX ...
    Synonym importing success, 0 rows are loaded.

  Importing package of schema TEST_INDEX ...
    Package importing success, 0 rows are loaded.

data importing success, 4 rows are loaded.
Logical import succeeded.

SQL> SELECT COUNT(*) FROM TBL_INDEX_WITH_NOLOGGING;

COUNT(*)            
--------------------
4                   

1 rows fetched.

SQL> 
SQL> conn sys/Huawei@123@127.0.0.1:1611

connected.

SQL> drop user if exists test_index cascade;

Succeed.

SQL> 


